{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AirBnB Reviews Topic Modelling: Full Review Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_review_data(directory):\n",
    "    \"\"\"Load Review Data\"\"\"\n",
    "    reviews_df = pd.read_csv(directory + 'interim/review_wrangled.csv', sep=';', lineterminator='\\n').drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    return reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select City\n",
    "country = 'united-states'\n",
    "city = 'san-francisco'\n",
    "\n",
    "# Directory\n",
    "directory = '../data/' + country + '/' + city + '/'\n",
    "\n",
    "# Load Data\n",
    "reviews_df = load_review_data(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>comments</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_count</th>\n",
       "      <th>name_entities</th>\n",
       "      <th>name_entities_count</th>\n",
       "      <th>comments_no_ne</th>\n",
       "      <th>no_ne_tokens</th>\n",
       "      <th>no_ne_tokens_count</th>\n",
       "      <th>nouns</th>\n",
       "      <th>nouns_counts</th>\n",
       "      <th>verbs</th>\n",
       "      <th>verbs_counts</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>adjectives_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>958</td>\n",
       "      <td>5977</td>\n",
       "      <td>2009-07-23</td>\n",
       "      <td>Our experience was, without a doubt, a five st...</td>\n",
       "      <td>['experience', 'without', 'doubt', 'five', 'st...</td>\n",
       "      <td>47</td>\n",
       "      <td>['David', 'Haight', 'Castro', 'Golden Gate Par...</td>\n",
       "      <td>5</td>\n",
       "      <td>Our experience was, without a doubt, a five st...</td>\n",
       "      <td>['experience', 'without', 'doubt', 'five', 'st...</td>\n",
       "      <td>39</td>\n",
       "      <td>['experience', 'doubt', 'star', 'experience', ...</td>\n",
       "      <td>30</td>\n",
       "      <td>[u'be', u'be', 'accomodating', u'honor', u'be'...</td>\n",
       "      <td>10</td>\n",
       "      <td>['consummate', 'full', 'perfect', 'full', 'clo...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>958</td>\n",
       "      <td>6660</td>\n",
       "      <td>2009-08-03</td>\n",
       "      <td>Returning to San Francisco is a rejuvenating t...</td>\n",
       "      <td>['returning', 'san', 'francisco', 'rejuvenatin...</td>\n",
       "      <td>36</td>\n",
       "      <td>['San Francisco', 'Holly', 'David']</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning to  is a rejuvenating thrill but thi...</td>\n",
       "      <td>['returning', 'rejuvenating', 'thrill', 'time'...</td>\n",
       "      <td>32</td>\n",
       "      <td>['san', 'francisco', 'rejuvenating', 'thrill',...</td>\n",
       "      <td>19</td>\n",
       "      <td>[u'return', u'be', u'be', u'enhance', u'renova...</td>\n",
       "      <td>14</td>\n",
       "      <td>['great', 'local', 'such', 'amenable']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>11519</td>\n",
       "      <td>2009-09-27</td>\n",
       "      <td>We were very pleased with the accommodations a...</td>\n",
       "      <td>['pleased', u'accommodation', 'friendly', 'nei...</td>\n",
       "      <td>67</td>\n",
       "      <td>['David', 'Haight Street', 'Castro Street']</td>\n",
       "      <td>3</td>\n",
       "      <td>We were very pleased with the accommodations a...</td>\n",
       "      <td>['pleased', u'accommodation', 'friendly', 'nei...</td>\n",
       "      <td>62</td>\n",
       "      <td>[u'accommodation', 'neighborhood', 'bed', 'fut...</td>\n",
       "      <td>41</td>\n",
       "      <td>[u'be', u'be', 'make', u'be', u'have', u'be', ...</td>\n",
       "      <td>21</td>\n",
       "      <td>['pleased', 'friendly', 'able', 'second', 'hel...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id     id        date  \\\n",
       "0         958   5977  2009-07-23   \n",
       "1         958   6660  2009-08-03   \n",
       "2         958  11519  2009-09-27   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Our experience was, without a doubt, a five st...   \n",
       "1  Returning to San Francisco is a rejuvenating t...   \n",
       "2  We were very pleased with the accommodations a...   \n",
       "\n",
       "                                              tokens  tokens_count  \\\n",
       "0  ['experience', 'without', 'doubt', 'five', 'st...            47   \n",
       "1  ['returning', 'san', 'francisco', 'rejuvenatin...            36   \n",
       "2  ['pleased', u'accommodation', 'friendly', 'nei...            67   \n",
       "\n",
       "                                       name_entities  name_entities_count  \\\n",
       "0  ['David', 'Haight', 'Castro', 'Golden Gate Par...                    5   \n",
       "1                ['San Francisco', 'Holly', 'David']                    3   \n",
       "2        ['David', 'Haight Street', 'Castro Street']                    3   \n",
       "\n",
       "                                      comments_no_ne  \\\n",
       "0  Our experience was, without a doubt, a five st...   \n",
       "1  Returning to  is a rejuvenating thrill but thi...   \n",
       "2  We were very pleased with the accommodations a...   \n",
       "\n",
       "                                        no_ne_tokens  no_ne_tokens_count  \\\n",
       "0  ['experience', 'without', 'doubt', 'five', 'st...                  39   \n",
       "1  ['returning', 'rejuvenating', 'thrill', 'time'...                  32   \n",
       "2  ['pleased', u'accommodation', 'friendly', 'nei...                  62   \n",
       "\n",
       "                                               nouns  nouns_counts  \\\n",
       "0  ['experience', 'doubt', 'star', 'experience', ...            30   \n",
       "1  ['san', 'francisco', 'rejuvenating', 'thrill',...            19   \n",
       "2  [u'accommodation', 'neighborhood', 'bed', 'fut...            41   \n",
       "\n",
       "                                               verbs  verbs_counts  \\\n",
       "0  [u'be', u'be', 'accomodating', u'honor', u'be'...            10   \n",
       "1  [u'return', u'be', u'be', u'enhance', u'renova...            14   \n",
       "2  [u'be', u'be', 'make', u'be', u'have', u'be', ...            21   \n",
       "\n",
       "                                          adjectives  adjectives_counts  \n",
       "0  ['consummate', 'full', 'perfect', 'full', 'clo...                  6  \n",
       "1             ['great', 'local', 'such', 'amenable']                  4  \n",
       "2  ['pleased', 'friendly', 'able', 'second', 'hel...                 16  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\"\"\"String Lists to Lists\"\"\"\n",
    "reviews_df['tokens'] = reviews_df['tokens'].map(lambda x: ast.literal_eval(x))\n",
    "reviews_df['name_entities'] = reviews_df['name_entities'].map(lambda x: ast.literal_eval(x))\n",
    "reviews_df['no_ne_tokens'] = reviews_df['no_ne_tokens'].map(lambda x: ast.literal_eval(x))\n",
    "reviews_df['nouns'] = reviews_df['nouns'].map(lambda x: ast.literal_eval(x))\n",
    "reviews_df['verbs'] = reviews_df['verbs'].map(lambda x: ast.literal_eval(x))\n",
    "reviews_df['adjectives'] = reviews_df['adjectives'].map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python2.7/site-packages/cryptography/hazmat/primitives/constant_time.py:26: CryptographyDeprecationWarning: Support for your Python version is deprecated. The next version of cryptography will remove support. Please upgrade to a 2.7.x release that supports hmac.compare_digest as soon as possible.\n",
      "  utils.PersistentlyDeprecated2018,\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import time\n",
    "ldam = LdaMulticore\n",
    "\n",
    "# LDA Model Inputs\n",
    "num_topics = 50\n",
    "num_words = 10\n",
    "passes = 50\n",
    "\n",
    "# Get Review Tokens\n",
    "token_texts = list(reviews_df['tokens'].values)\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(token_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in token_texts]\n",
    "\n",
    "# Get Start Time\n",
    "start_time = time.time()\n",
    "\n",
    "# LDA Model\n",
    "ldam_model = ldam(common_corpus, num_topics=num_topics, id2word=common_dictionary, passes=passes)\n",
    "model_end_time = time.time() # Model End Time\n",
    "\n",
    "# LDA Results\n",
    "results = ldam_model.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "result_time = time.time() # Results Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6543464689122307"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time For LDA Model\n",
    "(model_end_time - start_time)/60/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "ldam_model.save('../models/ldam_reviews_50topics_10words_50passes_full.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results):\n",
    "    for index, results in results:\n",
    "        print(str(index) + ': ' + str(', '.join(results.split('\"')[1::2])))\n",
    "        \n",
    "def display_results_no_duplicates(results):\n",
    "    all_lists = []\n",
    "    for index, result in results:\n",
    "        all_lists = all_lists + result.split('\"')[1::2]\n",
    "    \n",
    "    # Get Counts of each word\n",
    "    counts = pd.Series(all_lists).value_counts()\n",
    "    no_duplicates = counts[counts == 1].index\n",
    "    \n",
    "    for index, result in results:\n",
    "        print(str(index) + ': ' + str(', '.join([word for word in result.split('\"')[1::2] if word in no_duplicates])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ben, tower, greg, debbie, vista, siempre, nikki, venue, coit, cocina\n",
      "1: und, die, sehr, ist, wir, der, war, man, mit, das\n",
      "2: n't, place, would, room, night, bit, stay, noise, one, nice\n",
      "3: day, back, garden, morning, night, sunset, lovely, loved, one, wonderful\n",
      "4: city, place, quiet, great, perfect, neighborhood, space, spot, studio, stay\n",
      "5: 10/10, charm, barbara, lady, face, chip, recommand, address, conforme, painted\n",
      "6: touch, breakfast, coffee, snack, thoughtful, wine, even, morning, left, provided\n",
      "7: great, gave, local, tip, recommendation, host, city, area, helpful, provided\n",
      "8: really, enjoyed, stay, thank, much, hospitality, cat, appreciated, thanks, staying\n",
      "9: san, francisco, fran, visit, perfect, trip, time, visiting, fransisco, explore\n",
      "10: room, bathroom, private, bedroom, clean, kitchen, living, space, bed, shared\n",
      "11: house, people, place, n't, meet, friendly, really, get, time, great\n",
      "12: per, casa, joyce, con, molto, zona, non, muito, una, com\n",
      "13: detail, michelle, gem, hidden, airbnb, attention, rob, jenny, sfo, website\n",
      "14: kitchen, bed, comfortable, well, towel, shower, bathroom, space, everything, need\n",
      "15: ..., accessible, easily, paul, bike, uber/lyft, app, readily, helen, whilst\n",
      "16: light, jeff, wish, longer, decor, art, unique, style, amy, natural\n",
      "17: check, late, even, early, arrived, time, accommodating, let, flight, last\n",
      "18: muy, que, para, con, una, todo, casa, del, los, est\n",
      "19: park, gate, golden, beach, close, ocean, bridge, near, walk, location\n",
      "20: experience, airbnb, first, make, sure, went, time, way, beyond, guest\n",
      "21: est, nous, pour, bien, le, dans, une, avec, de, pa\n",
      "22: great, location, place, stay, host, clean, would, comfortable, super, excellent\n",
      "23: easy, check, communication, access, check-in, clean, super, communicate, made, instruction\n",
      "24: view, amazing, beautiful, city, michael, incredible, house, gorgeous, absolutely, bay\n",
      "25: hill, communicative, valley, noe, top, sarah, steep, tom, potrero, suzanne\n",
      "26: best, one, stayed, ever, place, airbnb, everything, 've, amazing, could\n",
      "27: quick, question, always, quickly, respond, response, available, responded, message, john\n",
      "28: mary, linda, dan, max, green, nicole, situation, nathan, repeat, grill\n",
      "29: appartement, rent, impeccable, no, grand, var, disponible, med, dont, ron\n",
      "30: star, without, five, joe, easier, hesitation, recommending, joy, trader, leo\n",
      "31: cottage, jason, james, victor, cindy, mom, laura, pete, rachel, mother\n",
      "32: n't, could, better, hotel, property, much, air, asked, ask, bnb\n",
      "33: everything, needed, exactly, need, described, apartment, picture, stay, perfect, sure\n",
      "34: downtown, walk, minute, bus, uber, easy, get, away, bart, city\n",
      "35: parking, car, street, family, find, easy, house, space, park, spot\n",
      "36: guy, peter, appartment, kathy, total, fall, restaurants, kommen, gastgeberin, pictures\n",
      "37: walking, distance, within, restaurant, square, location, union, many, wharf, fisherman\n",
      "38: wonderful, host, stay, comfortable, clean, beautiful, home, location, lovely, would\n",
      "39: home, feel, felt, like, made, welcome, make, beautiful, comfortable, safe\n",
      "40: good, location, value, price, communication, facility, place, service, reasonable, elizabeth\n",
      "41: stay, back, place, definitely, would, time, come, next, trip, visit\n",
      "42: apartment, mission, well, located, public, district, transport, castro, close, street\n",
      "43: arrival, day, reservation, host, upon, posting, automated, canceled, tony, sara\n",
      "44: restaurant, great, shop, bar, close, coffee, walk, store, nearby, location\n",
      "45: hosting, nick, okay, painted, perfekt, yes, ladies, auto, labeled, richard\n",
      "46: flat, group, center, conference, judy, kevin, soma, event, hassle, moscone\n",
      "47: nice, place, clean, really, super, room, stay, bed, house, comfortable\n",
      "48: josh, jean, adam, diana, memory, rooms, christmas, ian, complex, nature\n",
      "49: recommend, would, place, highly, stay, definitely, great, clean, staying, anyone\n"
     ]
    }
   ],
   "source": [
    "display_results(results[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ben, tower, greg, debbie, vista, siempre, nikki, venue, coit, cocina\n",
      "1: und, die, sehr, ist, wir, der, war, man, mit, das\n",
      "2: bit, noise\n",
      "3: garden, sunset, loved\n",
      "4: quiet, neighborhood, studio\n",
      "5: 10/10, charm, barbara, lady, face, chip, recommand, address, conforme\n",
      "6: touch, breakfast, snack, thoughtful, wine, left\n",
      "7: gave, local, tip, recommendation, area, helpful\n",
      "8: enjoyed, thank, hospitality, cat, appreciated, thanks\n",
      "9: san, francisco, fran, visiting, fransisco, explore\n",
      "10: private, bedroom, living, shared\n",
      "11: people, meet, friendly\n",
      "12: per, joyce, molto, zona, non, muito, com\n",
      "13: detail, michelle, gem, hidden, attention, rob, jenny, sfo, website\n",
      "14: towel, shower\n",
      "15: ..., accessible, easily, paul, bike, uber/lyft, app, readily, helen, whilst\n",
      "16: light, jeff, wish, longer, decor, art, unique, style, amy, natural\n",
      "17: late, early, arrived, accommodating, let, flight, last\n",
      "18: muy, que, para, todo, del, los\n",
      "19: gate, golden, beach, ocean, bridge, near\n",
      "20: experience, first, went, way, beyond, guest\n",
      "21: nous, pour, bien, le, dans, une, avec, de, pa\n",
      "22: excellent\n",
      "23: access, check-in, communicate, instruction\n",
      "24: view, michael, incredible, gorgeous, absolutely, bay\n",
      "25: hill, communicative, valley, noe, top, sarah, steep, tom, potrero, suzanne\n",
      "26: best, stayed, ever, 've\n",
      "27: quick, question, always, quickly, respond, response, available, responded, message, john\n",
      "28: mary, linda, dan, max, green, nicole, situation, nathan, repeat, grill\n",
      "29: appartement, rent, impeccable, no, grand, var, disponible, med, dont, ron\n",
      "30: star, without, five, joe, easier, hesitation, recommending, joy, trader, leo\n",
      "31: cottage, jason, james, victor, cindy, mom, laura, pete, rachel, mother\n",
      "32: better, hotel, property, air, asked, ask, bnb\n",
      "33: needed, exactly, described, picture\n",
      "34: downtown, minute, bus, uber, away, bart\n",
      "35: parking, car, family, find\n",
      "36: guy, peter, appartment, kathy, total, fall, restaurants, kommen, gastgeberin, pictures\n",
      "37: walking, distance, within, square, union, many, wharf, fisherman\n",
      "38: \n",
      "39: feel, felt, like, welcome, safe\n",
      "40: good, value, price, facility, service, reasonable, elizabeth\n",
      "41: come, next\n",
      "42: mission, located, public, district, transport, castro\n",
      "43: arrival, reservation, upon, posting, automated, canceled, tony, sara\n",
      "44: shop, bar, store, nearby\n",
      "45: hosting, nick, okay, perfekt, yes, ladies, auto, labeled, richard\n",
      "46: flat, group, center, conference, judy, kevin, soma, event, hassle, moscone\n",
      "47: \n",
      "48: josh, jean, adam, diana, memory, rooms, christmas, ian, complex, nature\n",
      "49: recommend, highly, anyone\n"
     ]
    }
   ],
   "source": [
    "display_results_no_duplicates(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity: -12.050553834102327\n",
      "\n",
      "Coherence Score: 0.5659598978242838\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ' + str(ldam_model.log_perplexity(common_corpus)))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=ldam_model, texts=token_texts, dictionary=common_dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ' + str(coherence_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30 Topics 10 Words 1 Passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import time\n",
    "ldam = LdaMulticore\n",
    "\n",
    "# LDA Model Inputs\n",
    "num_topics = 30\n",
    "num_words = 10\n",
    "passes = 10\n",
    "\n",
    "# Get Review Tokens\n",
    "token_texts1 = list(reviews_df['tokens'].values)\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary1 = Dictionary(token_texts1)\n",
    "common_corpus1 = [common_dictionary1.doc2bow(text) for text in token_texts1]\n",
    "\n",
    "# Get Start Time\n",
    "start_time = time.time()\n",
    "\n",
    "# LDA Model\n",
    "ldam_model1 = ldam(common_corpus1, num_topics=num_topics, id2word=common_dictionary1, passes=passes)\n",
    "model_end_time = time.time() # Model End Time\n",
    "\n",
    "# LDA Results\n",
    "results1 = ldam_model1.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "result_time = time.time() # Results Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22244854383998447"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time For LDA Model\n",
    "(model_end_time - start_time)/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: home, feel, like, felt, made, house, beautiful, staying, host, welcome\n",
      "1: view, kitchen, apartment, well, hill, beautiful, equipped, garden, deck, day\n",
      "2: und, die, sehr, ist, wir, war, der, mit, man, das\n",
      "3: arrival, day, host, reservation, upon, posting, automated, canceled, anna, responds\n",
      "4: parking, street, car, easy, find, spot, family, space, house, free\n",
      "5: stay, host, clean, located, comfortable, wonderful, well, quiet, apartment, lovely\n",
      "6: san, francisco, question, stay, quick, place, would, fran, respond, time\n",
      "7: coffee, touch, breakfast, snack, even, provided, wine, water, morning, fridge\n",
      "8: time, n't, night, day, room, even, check, would, late, early\n",
      "9: place, could, n't, time, stay, back, better, everything, perfect, stayed\n",
      "10: people, traveler, friendly, staff, brian, hostel, fun, mike, angela, community\n",
      "11: public, city, transportation, close, easy, great, area, transport, location, access\n",
      "12: great, restaurant, mission, place, close, shop, neighborhood, street, walk, quiet\n",
      "13: airbnb, best, experience, one, ever, first, ..., decorated, 've, stayed\n",
      "14: per, ryan, molto, casa, var, och, med, con, che, glenn\n",
      "15: checkin, nicole, carol, phil, straightforward, vor, auto, checkout, perfekt, landlord\n",
      "16: downtown, walk, bus, minute, uber, away, get, city, place, bart\n",
      "17: est, nous, pour, bien, le, dans, une, avec, de, pa\n",
      "18: sure, make, host, everything, stay, needed, made, great, gave, tip\n",
      "19: bed, comfortable, comfy, super, shower, air, clean, slept, bnb, hot\n",
      "20: hotel, detail, star, property, value, price, attention, top, excellent, cleanliness\n",
      "21: n't, place, good, noise, bit, little, room, location, would, night\n",
      "22: great, place, stay, recommend, would, location, host, highly, definitely, clean\n",
      "23: room, bathroom, private, space, clean, bedroom, kitchen, nice, bed, comfortable\n",
      "24: muy, que, con, para, casa, chris, una, del, todo, excelente\n",
      "25: nice, place, really, good, great, clean, stay, location, house, room\n",
      "26: dan, max, muito, com, recomendable, bem, mari, vivement, chambres, vel\n",
      "27: park, gate, golden, beach, close, ocean, bridge, near, walk, peter\n",
      "28: walking, distance, restaurant, within, location, great, square, shop, union, valley\n",
      "29: easy, great, everything, clean, check, place, stay, location, communication, exactly\n"
     ]
    }
   ],
   "source": [
    "display_results(results1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
