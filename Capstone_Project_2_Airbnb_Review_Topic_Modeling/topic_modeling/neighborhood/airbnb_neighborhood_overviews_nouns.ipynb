{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling Neighborhood Overview: Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "import glob as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data(country, city):\n",
    "    directory = 'data/' + country + '/' + city + '/'\n",
    "    csv_files = [file_name for file_name in glob.glob(directory + '*') if file_name[-4:] == '.csv']\n",
    "    \n",
    "    for file_loc in csv_files:\n",
    "        file_name = file_loc.split('/')[3]\n",
    "        \n",
    "        if file_name == 'listings_sample.csv':\n",
    "            #Read Listing Sample\n",
    "            listing_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "        elif file_name == 'reviews_sample.csv':\n",
    "            #Read Review Sample\n",
    "            reviews_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "        elif file_name == 'neighbourhoods_sample.csv':\n",
    "            #Read Neighborhoods\n",
    "            neighbourhoods_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "    return [listing_sample, reviews_sample, neighbourhoods_sample]\n",
    "\n",
    "\n",
    "def load_full_data(country, city):\n",
    "    directory = 'data/' + country + '/' + city + '/'\n",
    "    csv_files = [file_name for file_name in glob.glob(directory + '*') if file_name[-4:] == '.csv']\n",
    "    \n",
    "    for file_loc in csv_files:\n",
    "        file_name = file_loc.split('/')[3]\n",
    "        \n",
    "        if file_name == 'listings_full.csv':\n",
    "            #Read Listings\n",
    "            listings_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "        elif file_name == 'reviews_full.csv':\n",
    "            #Read Reviews\n",
    "            reviews_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "        elif file_name == 'calendar_full.csv':\n",
    "            #Read Calendar\n",
    "            calendar_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "    return [listings_full, reviews_full, calendar_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_sf = pd.read_csv('../sf/listings_detailed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_listing_full(listing_full_data):\n",
    "    \"\"\"Cleans listing_full.csv data\"\"\"\n",
    "    # Input Data\n",
    "    df = listing_full_data\n",
    "    \n",
    "    # String to Datetime\n",
    "    df['last_scraped'] = pd.to_datetime(df['last_scraped'])\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "    df['calendar_last_scraped'] = pd.to_datetime(df['calendar_last_scraped'])\n",
    "    df['first_review'] = pd.to_datetime(df['first_review'])\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "    \n",
    "    # String to Numeric\n",
    "    df['host_response_rate'] = pd.to_numeric(df['host_response_rate'].str[:-1]) / 100\n",
    "    df['price'] = pd.to_numeric(df['price'].str[1:].str.replace(',',''))\n",
    "    df['weekly_price'] = pd.to_numeric(df['weekly_price'].str[1:].str.replace(',',''))\n",
    "    df['monthly_price'] = pd.to_numeric(df['monthly_price'].str[1:].str.replace(',',''))\n",
    "    df['security_deposit'] = pd.to_numeric(df['security_deposit'].str[1:].str.replace(',',''))\n",
    "    df['cleaning_fee'] = pd.to_numeric(df['cleaning_fee'].str[1:].str.replace(',',''))\n",
    "    df['extra_people'] = pd.to_numeric(df['extra_people'].str[1:].str.replace(',',''))\n",
    "\n",
    "    # t/f to Numeric\n",
    "    df['host_is_superhost'] = (df['host_is_superhost'] == \"t\").astype(int)\n",
    "    df['host_has_profile_pic'] = (df['host_has_profile_pic'] == \"t\").astype(int)\n",
    "    df['host_identity_verified'] = (df['host_identity_verified'] == \"t\").astype(int)\n",
    "    df['is_location_exact'] = (df['is_location_exact'] == \"t\").astype(int)\n",
    "    df['has_availability'] = (df['has_availability'] == \"t\").astype(int)\n",
    "    df['requires_license'] = (df['requires_license'] == \"t\").astype(int)\n",
    "    df['instant_bookable'] = (df['instant_bookable'] == \"t\").astype(int)\n",
    "    df['is_business_travel_ready'] = (df['is_business_travel_ready'] == \"t\").astype(int)\n",
    "    df['require_guest_profile_picture'] = (df['require_guest_profile_picture'] == \"t\").astype(int)\n",
    "    df['require_guest_phone_verification'] = (df['require_guest_phone_verification'] == \"t\").astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_listings_sf = clean_listing_full(listings_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_detailed = clean_listings_sf.copy()\n",
    "\n",
    "ID = list(listings_detailed.iloc[:,:2].columns)\n",
    "\n",
    "ABOUT_COLS = list(listings_detailed.iloc[:,3:15].columns)\n",
    "\n",
    "PICS_COLS = list(listings_detailed.iloc[:,15:19].columns)\n",
    "\n",
    "HOST_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('host')])\n",
    "\n",
    "NEIGHBORHOOD_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('neighbourhood')])\n",
    "\n",
    "LOCATION_COLS = list(listings_detailed.iloc[:,37:51].columns)\n",
    "\n",
    "PROPERTY_COLS = list(listings_detailed.iloc[:,51:60].columns)\n",
    "\n",
    "PRICE_COLS = list(listings_detailed.iloc[:,60:67].columns)\n",
    "\n",
    "NIGHTS_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('mum')])\n",
    "\n",
    "AVAILABILITY_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('availability')])\n",
    "\n",
    "REVIEW_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('review')])\n",
    "\n",
    "SCRAPING_COLS = ['scrape_id','calendar_updated','calendar_last_scraped']\n",
    "\n",
    "ELSE_COLS = ['requires_license', 'license', 'jurisdiction_names', 'instant_bookable',\\\n",
    "             'is_business_travel_ready', 'cancellation_policy', 'require_guest_profile_picture',\\\n",
    "             'require_guest_phone_verification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_info = clean_listings_sf[ID + NEIGHBORHOOD_COLS + ABOUT_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7198 entries, 0 to 7197\n",
      "Data columns (total 18 columns):\n",
      "id                              7198 non-null int64\n",
      "listing_url                     7198 non-null object\n",
      "host_neighbourhood              6559 non-null object\n",
      "neighbourhood                   6660 non-null object\n",
      "neighbourhood_cleansed          7198 non-null object\n",
      "neighbourhood_group_cleansed    0 non-null float64\n",
      "last_scraped                    7198 non-null datetime64[ns]\n",
      "name                            7198 non-null object\n",
      "summary                         7000 non-null object\n",
      "space                           6109 non-null object\n",
      "description                     7183 non-null object\n",
      "experiences_offered             7198 non-null object\n",
      "neighborhood_overview           5310 non-null object\n",
      "notes                           4486 non-null object\n",
      "transit                         5238 non-null object\n",
      "access                          4794 non-null object\n",
      "interaction                     4931 non-null object\n",
      "house_rules                     5307 non-null object\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(15)\n",
      "memory usage: 1012.3+ KB\n"
     ]
    }
   ],
   "source": [
    "neighborhood_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews = neighborhood_info[['id','neighbourhood_cleansed','neighborhood_overview']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean & Tokenize Overview Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Initialize Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Get Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Get Puncuations\n",
    "punctuations = set(string.punctuation)\n",
    "\n",
    "def clean_text(doc):\n",
    "    \n",
    "    # remove all ascii\n",
    "    doc = re.sub(r'[^\\x00-\\x7F]+',' ', doc)\n",
    "\n",
    "    # Tokenize, Lemmatize, and Remove Stopwords\n",
    "    tokens = [lemmatizer.lemmatize(word).lower() for word in nltk.word_tokenize(doc) if word.lower() not in set(stop_words | punctuations)]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean & Tokenize Overviews\n",
    "neighborhood_overviews['tokens'] = neighborhood_overviews['neighborhood_overview'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews['clean_overviews'] = neighborhood_overviews['tokens'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_sentences(data):\n",
    "    # Tokenize each sentence into words: token_sentences\n",
    "    token_sentences = [nltk.word_tokenize(re.sub(r'[^\\x00-\\x7F]+',' ', sent)) for sent in data]\n",
    "\n",
    "    # Tag each tokenized sentence into parts of speech: pos_sentences\n",
    "    pos_sentences = [nltk.pos_tag(sent) for sent in token_sentences]\n",
    "    return pos_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TextExtraction with DS Skills Listing\n",
    "pos_overviews_neighborhood = get_pos_sentences(neighborhood_overviews['neighborhood_overview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns(pos_sentences):\n",
    "    \"\"\"Return Noun List\"\"\"\n",
    "    # Noun Codes\n",
    "    noun_code = ['NN','NNS','NNP','NNPS']\n",
    "    \n",
    "    # Get Nouns\n",
    "    noun_list = [[word[0].lower() for word in sent if word[1] in noun_code] for sent in pos_sentences]\n",
    "\n",
    "    #Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    noun_lem_list = [[lemmatizer.lemmatize(noun) for noun in noun_sent] for noun_sent in noun_list]\n",
    "        \n",
    "    return noun_lem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_overviews_neighborhood = get_nouns(pos_overviews_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews = neighborhood_overviews.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews['nouns'] = pd.Series(nouns_overviews_neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_texts_nouns = list(neighborhood_overviews['nouns'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(token_texts_nouns)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in token_texts_nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import time\n",
    "ldam = LdaMulticore\n",
    "\n",
    "num_topics = 50\n",
    "num_words = 5\n",
    "passes = 50\n",
    "\n",
    "# Get Start Time\n",
    "start_time = time.time()\n",
    "\n",
    "# LDA Model\n",
    "ldam_model = ldam(common_corpus, num_topics=num_topics, id2word=common_dictionary, passes=passes)\n",
    "model_end_time = time.time() # Model End Time\n",
    "\n",
    "# LDA Results\n",
    "results = ldam_model.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "result_time = time.time() # Results Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldam_model.save('../models/ldam_neighborhood_overviews_50topics_5words_50passes_nouns.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results):\n",
    "    for index, results in results:\n",
    "        print(str(index) + ': ' + str(', '.join(results.split('\"')[1::2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: store, restaurant, grocery, shop, block\n",
      "1: street, hill, north, beach, wharf\n",
      "2: super, entrance, grocer, safety, neighborhood\n",
      "3: block, street, park, mission, dolores\n",
      "4: pacific, height, fillmore, francisco, san\n",
      "5: san, francisco, mission, street, neighborhood\n",
      "6: bernal, height, park, neighborhood, view\n",
      "7: neighborhood, lot, people, family, bayview\n",
      "8: park, glen, canyon, neighborhood, village\n",
      "9: peak, twin, view, city, hill\n",
      "10: castro, neighborhood, francisco, san, restaurant\n",
      "11: center, city, san, francisco, head\n",
      "12: neighborhood, san, francisco, park, airport\n",
      "13: court, walk, tennis, park, playground\n",
      "14: airbnb, neighborhood, district, mission, restaurant\n",
      "15: san, francisco, neighborhood, life, city\n",
      "16: district, minute, financial, embarcadero, beach\n",
      "17: min, street, walk, polk, sf\n",
      "18: francisco, san, city, square, park\n",
      "19: access, bus, neighborhood, transportation, line\n",
      "20: block, restaurant, bar, door, corner\n",
      "21: park, haight, neighborhood, haight-ashbury, francisco\n",
      "22: san, francisco, neighborhood, west, portal\n",
      "23: city, restaurant, mission, francisco, san\n",
      "24: area, neighborhood, restaurant, park, mix\n",
      "25: hidden, book, city, place, shop\n",
      "26: francisco, san, minute, walk, car\n",
      "27: bay, san, francisco, t, mission\n",
      "28: street, mi, parking, couple, sf\n",
      "29: san, francisco, neighborhood, hill, city\n",
      "30: hill, potrero, street, city, view\n",
      "31: san, francisco, neighborhood, everything, city\n",
      "32: coffee, street, restaurant, block, neighborhood\n",
      "33: life, night, note, street, sf\n",
      "34: gate, golden, park, beach, block\n",
      "35: neighborhood, market, house, minute, street\n",
      "36: soma, san, museum, francisco, market\n",
      "37: street, neighborhood, apartment, area, height\n",
      "38: beach, ocean, sunset, zoo, park\n",
      "39: building, neighborhood, attraction, tenderloin, ferry\n",
      "40: neighborhood, street, restaurant, city, market\n",
      "41: street, restaurant, san, francisco, valley\n",
      "42: park, haight, alamo, square, neighborhood\n",
      "43: street, marina, gate, bridge, wharf\n",
      "44: mission, restaurant, bar, cafe, neighborhood\n",
      "45: food, coffee, thai, sushi, mexican\n",
      "46: hayes, valley, center, restaurant, hall\n",
      "47: union, square, restaurant, great, theater\n",
      "48: valley, neighborhood, noe, castro, mission\n",
      "49: balboa, street, geary, presidio, clement\n"
     ]
    }
   ],
   "source": [
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_no_duplicates(results):\n",
    "    all_lists = []\n",
    "    for index, result in results:\n",
    "        all_lists = all_lists + result.split('\"')[1::2]\n",
    "    \n",
    "    # Get Counts of each word\n",
    "    counts = pd.Series(all_lists).value_counts()\n",
    "    no_duplicates = counts[counts == 1].index\n",
    "    \n",
    "    for index, result in results:\n",
    "        print(str(index) + ': ' + str(', '.join([word for word in result.split('\"')[1::2] if word in no_duplicates])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: store, grocery\n",
      "1: north\n",
      "2: super, entrance, grocer, safety\n",
      "3: dolores\n",
      "4: pacific, fillmore\n",
      "5: \n",
      "6: bernal\n",
      "7: lot, people, family, bayview\n",
      "8: glen, canyon, village\n",
      "9: peak, twin\n",
      "10: \n",
      "11: head\n",
      "12: airport\n",
      "13: court, tennis, playground\n",
      "14: airbnb\n",
      "15: \n",
      "16: financial, embarcadero\n",
      "17: min, polk\n",
      "18: \n",
      "19: access, bus, transportation, line\n",
      "20: door, corner\n",
      "21: haight-ashbury\n",
      "22: west, portal\n",
      "23: \n",
      "24: mix\n",
      "25: hidden, book, place\n",
      "26: car\n",
      "27: bay, t\n",
      "28: mi, parking, couple\n",
      "29: \n",
      "30: potrero\n",
      "31: everything\n",
      "32: \n",
      "33: night, note\n",
      "34: golden\n",
      "35: house\n",
      "36: soma, museum\n",
      "37: apartment\n",
      "38: ocean, sunset, zoo\n",
      "39: building, attraction, tenderloin, ferry\n",
      "40: \n",
      "41: \n",
      "42: alamo\n",
      "43: marina, bridge\n",
      "44: cafe\n",
      "45: food, thai, sushi, mexican\n",
      "46: hayes, hall\n",
      "47: union, great, theater\n",
      "48: noe\n",
      "49: balboa, geary, presidio, clement\n"
     ]
    }
   ],
   "source": [
    "display_results_no_duplicates(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_by_neighborhood = neighborhood_overviews.groupby('neighbourhood_cleansed')[['nouns']].apply(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_texts_by_neighborhood = list(tokens_by_neighborhood['nouns'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary_by_neighborhood = Dictionary(token_texts_by_neighborhood)\n",
    "common_corpus_by_neighborhood = [common_dictionary_by_neighborhood.doc2bow(text) for text in token_texts_by_neighborhood]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import time\n",
    "ldam = LdaMulticore\n",
    "\n",
    "num_topics = 50\n",
    "num_words = 10\n",
    "passes = 50\n",
    "\n",
    "# Get Start Time\n",
    "start_time = time.time()\n",
    "\n",
    "# LDA Model\n",
    "ldam_model_by_neighborhood = ldam(common_corpus_by_neighborhood, num_topics=num_topics, id2word=common_dictionary_by_neighborhood, passes=passes)\n",
    "model_end_time = time.time() # Model End Time\n",
    "\n",
    "# LDA Results\n",
    "results_by_neighborhood = ldam_model_by_neighborhood.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "result_time = time.time() # Results Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldam_model_by_neighborhood.save('../models/ldam_overview_by_neighborhood_50topics_10words_50passes_verbs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: neighborhood, restaurant, san, block, park, francisco, street, city, gate, shop\n",
      "1: noe, valley, neighborhood, restaurant, street, shop, walk, block, mission, park\n",
      "2: neighborhood, restaurant, street, san, block, city, francisco, bar, park, minute\n",
      "3: francisco, neighborhood, restaurant, block, park, city, san, street, shop, mission\n",
      "4: park, gate, neighborhood, golden, restaurant, sunset, inner, block, shop, walk\n",
      "5: restaurant, francisco, block, street, neighborhood, san, city, park, mission, district\n",
      "6: neighborhood, san, street, block, francisco, park, restaurant, city, shop, district\n",
      "7: mission, neighborhood, restaurant, street, block, city, san, park, francisco, bernal\n",
      "8: restaurant, neighborhood, street, park, san, francisco, city, block, hayes, valley\n",
      "9: neighborhood, restaurant, street, block, city, park, san, francisco, distance, square\n",
      "10: park, glen, neighborhood, san, restaurant, francisco, bart, store, mission, city\n",
      "11: park, neighborhood, restaurant, san, city, block, francisco, mission, street, distance\n",
      "12: francisco, neighborhood, restaurant, street, san, park, city, hill, block, walk\n",
      "13: san, francisco, hill, square, wharf, district, chinatown, beach, street, fisherman\n",
      "14: neighborhood, restaurant, francisco, san, block, city, street, park, bar, district\n",
      "15: neighborhood, park, restaurant, block, city, street, san, francisco, bar, mission\n",
      "16: restaurant, park, neighborhood, san, block, francisco, street, city, mission, distance\n",
      "17: neighborhood, francisco, san, restaurant, street, city, park, distance, block, mission\n",
      "18: neighborhood, restaurant, francisco, san, street, park, block, mission, city, minute\n",
      "19: neighborhood, restaurant, park, block, san, francisco, street, city, bar, shop\n",
      "20: park, neighborhood, francisco, restaurant, san, block, city, street, mission, distance\n",
      "21: neighborhood, park, san, street, restaurant, block, francisco, city, shop, mission\n",
      "22: neighborhood, restaurant, park, francisco, block, san, street, shop, city, minute\n",
      "23: neighborhood, park, street, san, francisco, restaurant, block, city, shop, distance\n",
      "24: san, francisco, center, city, soma, head, market, restaurant, bay, museum\n",
      "25: restaurant, neighborhood, city, street, francisco, san, block, park, mission, bar\n",
      "26: neighborhood, san, francisco, street, marina, city, restaurant, block, distance, bridge\n",
      "27: wilemina, restaurant, neighborhood, park, francisco, block, beach, golden, gate, san\n",
      "28: francisco, san, neighborhood, city, park, block, restaurant, street, walk, shop\n",
      "29: mosaic, trail, joint, class, clement, presidio, biking, nightlife, world, music\n",
      "30: square, union, restaurant, neighborhood, francisco, san, city, hill, car, building\n",
      "31: castro, neighborhood, park, block, restaurant, street, mission, dolores, city, bar\n",
      "32: street, block, height, neighborhood, restaurant, pacific, fillmore, shop, presidio, park\n",
      "33: park, francisco, restaurant, san, neighborhood, block, street, city, walk, district\n",
      "34: restaurant, neighborhood, street, park, san, block, francisco, city, bar, shop\n",
      "35: san, restaurant, neighborhood, francisco, street, park, mission, city, block, hill\n",
      "36: neighborhood, park, restaurant, san, street, shop, francisco, block, city, mission\n",
      "37: hill, potrero, neighborhood, restaurant, street, san, city, francisco, view, block\n",
      "38: restaurant, neighborhood, san, francisco, block, city, street, park, shop, bar\n",
      "39: neighborhood, restaurant, park, street, hill, block, francisco, san, walk, bar\n",
      "40: neighborhood, restaurant, francisco, park, city, mission, san, street, block, district\n",
      "41: park, gate, block, golden, restaurant, neighborhood, beach, san, ocean, francisco\n",
      "42: neighborhood, restaurant, block, street, mission, francisco, city, san, park, bar\n",
      "43: park, neighborhood, haight, block, restaurant, gate, golden, san, francisco, cole\n",
      "44: ocean, sf, zoo, stonestown, mall, university, francisco, san, merced, state\n",
      "45: restaurant, neighborhood, park, francisco, street, block, san, city, shop, height\n",
      "46: restaurant, street, neighborhood, block, san, francisco, park, valley, mission, shop\n",
      "47: francisco, neighborhood, city, street, restaurant, san, mission, center, minute, block\n",
      "48: neighborhood, restaurant, park, street, city, francisco, san, block, mission, castro\n",
      "49: neighborhood, minute, francisco, san, city, street, restaurant, view, walk, park\n"
     ]
    }
   ],
   "source": [
    "display_results(results_by_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "1: noe\n",
      "2: \n",
      "3: \n",
      "4: sunset, inner\n",
      "5: \n",
      "6: \n",
      "7: bernal\n",
      "8: hayes\n",
      "9: \n",
      "10: glen, bart, store\n",
      "11: \n",
      "12: \n",
      "13: wharf, chinatown, fisherman\n",
      "14: \n",
      "15: \n",
      "16: \n",
      "17: \n",
      "18: \n",
      "19: \n",
      "20: \n",
      "21: \n",
      "22: \n",
      "23: \n",
      "24: soma, head, market, bay, museum\n",
      "25: \n",
      "26: marina, bridge\n",
      "27: wilemina\n",
      "28: \n",
      "29: mosaic, trail, joint, class, clement, biking, nightlife, world, music\n",
      "30: union, car, building\n",
      "31: dolores\n",
      "32: pacific, fillmore\n",
      "33: \n",
      "34: \n",
      "35: \n",
      "36: \n",
      "37: potrero\n",
      "38: \n",
      "39: \n",
      "40: \n",
      "41: \n",
      "42: \n",
      "43: haight, cole\n",
      "44: sf, zoo, stonestown, mall, university, merced, state\n",
      "45: \n",
      "46: \n",
      "47: \n",
      "48: \n",
      "49: \n"
     ]
    }
   ],
   "source": [
    "display_results_no_duplicates(results_by_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
