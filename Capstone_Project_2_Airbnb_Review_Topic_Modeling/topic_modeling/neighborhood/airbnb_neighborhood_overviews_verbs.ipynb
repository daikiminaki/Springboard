{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling Neighborhood Overview: Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "import glob as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data(country, city):\n",
    "    directory = 'data/' + country + '/' + city + '/'\n",
    "    csv_files = [file_name for file_name in glob.glob(directory + '*') if file_name[-4:] == '.csv']\n",
    "    \n",
    "    for file_loc in csv_files:\n",
    "        file_name = file_loc.split('/')[3]\n",
    "        \n",
    "        if file_name == 'listings_sample.csv':\n",
    "            #Read Listing Sample\n",
    "            listing_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "        elif file_name == 'reviews_sample.csv':\n",
    "            #Read Review Sample\n",
    "            reviews_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "        elif file_name == 'neighbourhoods_sample.csv':\n",
    "            #Read Neighborhoods\n",
    "            neighbourhoods_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "    return [listing_sample, reviews_sample, neighbourhoods_sample]\n",
    "\n",
    "\n",
    "def load_full_data(country, city):\n",
    "    directory = 'data/' + country + '/' + city + '/'\n",
    "    csv_files = [file_name for file_name in glob.glob(directory + '*') if file_name[-4:] == '.csv']\n",
    "    \n",
    "    for file_loc in csv_files:\n",
    "        file_name = file_loc.split('/')[3]\n",
    "        \n",
    "        if file_name == 'listings_full.csv':\n",
    "            #Read Listings\n",
    "            listings_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "        elif file_name == 'reviews_full.csv':\n",
    "            #Read Reviews\n",
    "            reviews_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "        elif file_name == 'calendar_full.csv':\n",
    "            #Read Calendar\n",
    "            calendar_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "    return [listings_full, reviews_full, calendar_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_sf = pd.read_csv('../sf/listings_detailed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_listing_full(listing_full_data):\n",
    "    \"\"\"Cleans listing_full.csv data\"\"\"\n",
    "    # Input Data\n",
    "    df = listing_full_data\n",
    "    \n",
    "    # String to Datetime\n",
    "    df['last_scraped'] = pd.to_datetime(df['last_scraped'])\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "    df['calendar_last_scraped'] = pd.to_datetime(df['calendar_last_scraped'])\n",
    "    df['first_review'] = pd.to_datetime(df['first_review'])\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "    \n",
    "    # String to Numeric\n",
    "    df['host_response_rate'] = pd.to_numeric(df['host_response_rate'].str[:-1]) / 100\n",
    "    df['price'] = pd.to_numeric(df['price'].str[1:].str.replace(',',''))\n",
    "    df['weekly_price'] = pd.to_numeric(df['weekly_price'].str[1:].str.replace(',',''))\n",
    "    df['monthly_price'] = pd.to_numeric(df['monthly_price'].str[1:].str.replace(',',''))\n",
    "    df['security_deposit'] = pd.to_numeric(df['security_deposit'].str[1:].str.replace(',',''))\n",
    "    df['cleaning_fee'] = pd.to_numeric(df['cleaning_fee'].str[1:].str.replace(',',''))\n",
    "    df['extra_people'] = pd.to_numeric(df['extra_people'].str[1:].str.replace(',',''))\n",
    "\n",
    "    # t/f to Numeric\n",
    "    df['host_is_superhost'] = (df['host_is_superhost'] == \"t\").astype(int)\n",
    "    df['host_has_profile_pic'] = (df['host_has_profile_pic'] == \"t\").astype(int)\n",
    "    df['host_identity_verified'] = (df['host_identity_verified'] == \"t\").astype(int)\n",
    "    df['is_location_exact'] = (df['is_location_exact'] == \"t\").astype(int)\n",
    "    df['has_availability'] = (df['has_availability'] == \"t\").astype(int)\n",
    "    df['requires_license'] = (df['requires_license'] == \"t\").astype(int)\n",
    "    df['instant_bookable'] = (df['instant_bookable'] == \"t\").astype(int)\n",
    "    df['is_business_travel_ready'] = (df['is_business_travel_ready'] == \"t\").astype(int)\n",
    "    df['require_guest_profile_picture'] = (df['require_guest_profile_picture'] == \"t\").astype(int)\n",
    "    df['require_guest_phone_verification'] = (df['require_guest_phone_verification'] == \"t\").astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_listings_sf = clean_listing_full(listings_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_detailed = clean_listings_sf.copy()\n",
    "\n",
    "ID = list(listings_detailed.iloc[:,:2].columns)\n",
    "\n",
    "ABOUT_COLS = list(listings_detailed.iloc[:,3:15].columns)\n",
    "\n",
    "PICS_COLS = list(listings_detailed.iloc[:,15:19].columns)\n",
    "\n",
    "HOST_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('host')])\n",
    "\n",
    "NEIGHBORHOOD_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('neighbourhood')])\n",
    "\n",
    "LOCATION_COLS = list(listings_detailed.iloc[:,37:51].columns)\n",
    "\n",
    "PROPERTY_COLS = list(listings_detailed.iloc[:,51:60].columns)\n",
    "\n",
    "PRICE_COLS = list(listings_detailed.iloc[:,60:67].columns)\n",
    "\n",
    "NIGHTS_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('mum')])\n",
    "\n",
    "AVAILABILITY_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('availability')])\n",
    "\n",
    "REVIEW_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('review')])\n",
    "\n",
    "SCRAPING_COLS = ['scrape_id','calendar_updated','calendar_last_scraped']\n",
    "\n",
    "ELSE_COLS = ['requires_license', 'license', 'jurisdiction_names', 'instant_bookable',\\\n",
    "             'is_business_travel_ready', 'cancellation_policy', 'require_guest_profile_picture',\\\n",
    "             'require_guest_phone_verification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_info = clean_listings_sf[ID + NEIGHBORHOOD_COLS + ABOUT_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7198 entries, 0 to 7197\n",
      "Data columns (total 18 columns):\n",
      "id                              7198 non-null int64\n",
      "listing_url                     7198 non-null object\n",
      "host_neighbourhood              6559 non-null object\n",
      "neighbourhood                   6660 non-null object\n",
      "neighbourhood_cleansed          7198 non-null object\n",
      "neighbourhood_group_cleansed    0 non-null float64\n",
      "last_scraped                    7198 non-null datetime64[ns]\n",
      "name                            7198 non-null object\n",
      "summary                         7000 non-null object\n",
      "space                           6109 non-null object\n",
      "description                     7183 non-null object\n",
      "experiences_offered             7198 non-null object\n",
      "neighborhood_overview           5310 non-null object\n",
      "notes                           4486 non-null object\n",
      "transit                         5238 non-null object\n",
      "access                          4794 non-null object\n",
      "interaction                     4931 non-null object\n",
      "house_rules                     5307 non-null object\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(15)\n",
      "memory usage: 1012.3+ KB\n"
     ]
    }
   ],
   "source": [
    "neighborhood_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews = neighborhood_info[['id','neighbourhood_cleansed','neighborhood_overview']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean & Tokenize Overview Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Initialize Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Get Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Get Puncuations\n",
    "punctuations = set(string.punctuation)\n",
    "\n",
    "def clean_text(doc):\n",
    "    \n",
    "    # remove all ascii\n",
    "    doc = re.sub(r'[^\\x00-\\x7F]+',' ', doc)\n",
    "\n",
    "    # Tokenize, Lemmatize, and Remove Stopwords\n",
    "    tokens = [lemmatizer.lemmatize(word).lower() for word in nltk.word_tokenize(doc) if word.lower() not in set(stop_words | punctuations)]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean & Tokenize Overviews\n",
    "neighborhood_overviews['tokens'] = neighborhood_overviews['neighborhood_overview'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews['clean_overviews'] = neighborhood_overviews['tokens'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_sentences(data):\n",
    "    # Tokenize each sentence into words: token_sentences\n",
    "    token_sentences = [nltk.word_tokenize(re.sub(r'[^\\x00-\\x7F]+',' ', sent)) for sent in data]\n",
    "\n",
    "    # Tag each tokenized sentence into parts of speech: pos_sentences\n",
    "    pos_sentences = [nltk.pos_tag(sent) for sent in token_sentences]\n",
    "    return pos_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TextExtraction with DS Skills Listing\n",
    "pos_overviews_neighborhood = get_pos_sentences(neighborhood_overviews['neighborhood_overview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verbs(pos_sentences):\n",
    "    \"\"\"Return Verbs\"\"\"\n",
    "    # Codes\n",
    "    verb_code = ['VBG','VB','VBD','VBN','VBZ']\n",
    "\n",
    "    # Get List of Adjectives\n",
    "    verb_list = [[word[0].lower() for word in sent if word[1] in verb_code] for sent in pos_sentences]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    verb_lem_list = [[lemmatizer.lemmatize(verb, 'v') for verb in verb_sent] for verb_sent in verb_list]\n",
    "        \n",
    "    return verb_lem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_overviews_neighborhood = get_verbs(pos_overviews_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews = neighborhood_overviews.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews['verbs'] = pd.Series(verbs_overviews_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews['verb_count'] = neighborhood_overviews['verbs'].map(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x116c9a610>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neighborhood_overviews['verb_count'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_texts = list(neighborhood_overviews['verbs'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(token_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in token_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import time\n",
    "ldam = LdaMulticore\n",
    "\n",
    "num_topics = 50\n",
    "num_words = 5\n",
    "passes = 50\n",
    "\n",
    "# Get Start Time\n",
    "start_time = time.time()\n",
    "\n",
    "# LDA Model\n",
    "ldam_model = ldam(common_corpus, num_topics=num_topics, id2word=common_dictionary, passes=passes)\n",
    "model_end_time = time.time() # Model End Time\n",
    "\n",
    "# LDA Results\n",
    "results = ldam_model.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "result_time = time.time() # Results Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldam_model.save('../models/ldam_neighborhood_overviews_50topics_5words_50passes_verbs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results):\n",
    "    for index, results in results:\n",
    "        print(str(index) + ': ' + str(', '.join(results.split('\"')[1::2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: be, situate, walk, use, know\n",
      "1: be, shop, walk, try, explore\n",
      "2: 's, be, have, know, compare\n",
      "3: s, be, stay, stun, describe\n",
      "4: be, feel, home, travel, range\n",
      "5: do, have, be, see, neighborhood\n",
      "6: find, be, step, walk, serve\n",
      "7: check, take, be, allow, walk\n",
      "8: be, eat, grab, drink, face\n",
      "9: take, be, orient, drive, open\n",
      "10: give, hear, walk, make, 's\n",
      "11: be, have, live, rat, know\n",
      "12: feature, be, nestle, represent, crowd\n",
      "13: be, bustle, din, locate, rent\n",
      "14: explore, be, offer, walk, catch\n",
      "15: be, include, head, meet, host\n",
      "16: walk, be, locate, rid, highway\n",
      "17: offer, have, be, boast, inspire\n",
      "18: be, explore, ride, put, spend\n",
      "19: be, have, bring, recommend, do\n",
      "20: be, excite, access, trail, boast\n",
      "21: be, choose, walk, raise, invite\n",
      "22: be, connect, have, anywhere, lay\n",
      "23: go, be, make, have, visit\n",
      "24: run, hike, be, walk, list\n",
      "25: be, walk, have, lie, make\n",
      "26: come, need, be, close, walk\n",
      "27: create, seek, satisfy, lose, be\n",
      "28: get, be, have, take, locate\n",
      "29: work, be, tour, hang, ask\n",
      "30: be, fill, locate, walk, grow\n",
      "31: be, call, have, walk, consider\n",
      "32: walk, be, sit, relax, *\n",
      "33: charm, be, love, start, walk\n",
      "34: be, locate, have, breathtaking, overlook\n",
      "35: help, provide, believe, appear, include\n",
      "36: look, be, change, like, attract\n",
      "37: see, park, be, dolores, leave\n",
      "38: be, have, take, locate, come\n",
      "39: be, watch, play, walk, swim\n",
      "40: enjoy, hide, be, visit, stay\n",
      "41: be, name, line, just, evolve\n",
      "42: be, know, become, remain, make\n",
      "43: be, provide, block, bike, renowned\n",
      "44: be, surround, border, keep, appreciate\n",
      "45: be, refer, build, know, contain\n",
      "46: include, be, walk, amaze, bus\n",
      "47: downtown, be, walk, take, stay\n",
      "48: be, multiple, bring, give, throw\n",
      "49: be, want, have, mean, tuck\n"
     ]
    }
   ],
   "source": [
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_no_duplicates(results):\n",
    "    all_lists = []\n",
    "    for index, result in results:\n",
    "        all_lists = all_lists + result.split('\"')[1::2]\n",
    "    \n",
    "    # Get Counts of each word\n",
    "    counts = pd.Series(all_lists).value_counts()\n",
    "    no_duplicates = counts[counts == 1].index\n",
    "    \n",
    "    for index, result in results:\n",
    "        print(str(index) + ': ' + str(', '.join([word for word in result.split('\"')[1::2] if word in no_duplicates])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: situate, use\n",
      "1: shop, try\n",
      "2: compare\n",
      "3: s, stun, describe\n",
      "4: feel, home, travel, range\n",
      "5: neighborhood\n",
      "6: find, step, serve\n",
      "7: check, allow\n",
      "8: eat, grab, drink, face\n",
      "9: orient, drive, open\n",
      "10: hear\n",
      "11: live, rat\n",
      "12: feature, nestle, represent, crowd\n",
      "13: bustle, din, rent\n",
      "14: catch\n",
      "15: head, meet, host\n",
      "16: rid, highway\n",
      "17: inspire\n",
      "18: ride, put, spend\n",
      "19: recommend\n",
      "20: excite, access, trail\n",
      "21: choose, raise, invite\n",
      "22: connect, anywhere, lay\n",
      "23: go\n",
      "24: run, hike, list\n",
      "25: lie\n",
      "26: need, close\n",
      "27: create, seek, satisfy, lose\n",
      "28: get\n",
      "29: work, tour, hang, ask\n",
      "30: fill, grow\n",
      "31: call, consider\n",
      "32: sit, relax, *\n",
      "33: charm, love, start\n",
      "34: breathtaking, overlook\n",
      "35: help, believe, appear\n",
      "36: look, change, like, attract\n",
      "37: park, dolores, leave\n",
      "38: \n",
      "39: watch, play, swim\n",
      "40: enjoy, hide\n",
      "41: name, line, just, evolve\n",
      "42: become, remain\n",
      "43: block, bike, renowned\n",
      "44: surround, border, keep, appreciate\n",
      "45: refer, build, contain\n",
      "46: amaze, bus\n",
      "47: downtown\n",
      "48: multiple, throw\n",
      "49: want, mean, tuck\n"
     ]
    }
   ],
   "source": [
    "display_results_no_duplicates(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_by_neighborhood = neighborhood_overviews.groupby('neighbourhood_cleansed')[['verbs']].apply(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_texts_by_neighborhood = list(neighborhood_overviews['verbs'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary_by_neighborhood = Dictionary(token_texts_by_neighborhood)\n",
    "common_corpus_by_neighborhood = [common_dictionary_by_neighborhood.doc2bow(text) for text in token_texts_by_neighborhood]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import time\n",
    "ldam = LdaMulticore\n",
    "\n",
    "num_topics = 50\n",
    "num_words = 10\n",
    "passes = 50\n",
    "\n",
    "# Get Start Time\n",
    "start_time = time.time()\n",
    "\n",
    "# LDA Model\n",
    "ldam_model_by_neighborhood = ldam(common_corpus_by_neighborhood, num_topics=num_topics, id2word=common_dictionary_by_neighborhood, passes=passes)\n",
    "model_end_time = time.time() # Model End Time\n",
    "\n",
    "# LDA Results\n",
    "results_by_neighborhood = ldam_model_by_neighborhood.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "result_time = time.time() # Results Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldam_model_by_neighborhood.save('../models/ldam_overview_by_neighborhood_50topics_10words_50passes_verbs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: be, offer, explore, try, walk, thrive, appeal, mix, allow, stop\n",
      "1: be, climb, take, locate, walk, show, commute, occupy, shuttle, 's\n",
      "2: be, serve, live, find, travel, stock, discover, own, come, give\n",
      "3: be, visit, get, tuck, host, offer, maintain, own, sip, locate\n",
      "4: be, shop, locate, sit, walk, drive, anywhere, lie, freeway, teem\n",
      "5: see, be, watch, neighborhood, walk, do, have, take, surf, lay\n",
      "6: stay, bike, beautiful, support, carry, happen, imagine, frame, bart, o\n",
      "7: be, border, have, say, locate, make, populate, ask, walk, famed\n",
      "8: open, reach, rent, own, be, invite, beloved, laugh, designate, bike\n",
      "9: run, charm, be, have, create, roll, walk, encompass, locate, stop\n",
      "10: be, situate, walk, stun, feel, know, explore, get, happen, live\n",
      "11: be, din, start, grab, locate, walk, remodel, have, love, jump\n",
      "12: be, feature, name, build, just, evolve, range, have, detach, wind\n",
      "13: enjoy, park, be, walk, have, list, dolores, head, leave, jog\n",
      "14: be, have, take, locate, 's, see, paint, know, cost, do\n",
      "15: be, overlook, connect, breathtaking, locate, melt, have, remove, nestle, provide\n",
      "16: be, downtown, need, locate, walk, have, relax, take, know, depend\n",
      "17: be, hide, block, walk, turn, cook, know, dance, situate, whisk\n",
      "18: surround, be, walk, 's, offer, explore, line, try, have, catch\n",
      "19: hike, be, have, leave, walk, require, pack, mention, set, make\n",
      "20: be, locate, explore, put, check, stop, wander, spend, learn, occupy\n",
      "21: be, eat, bring, walk, drink, locate, have, do, grab, lose\n",
      "22: be, have, live, locate, rat, know, become, offer, vote, make\n",
      "23: be, have, see, locate, walk, offer, accord, own, picnic, buy\n",
      "24: be, have, offer, crowd, transform, contain, ride, face, head, locate\n",
      "25: be, come, take, go, have, renovate, hold, develop, locate, dominate\n",
      "26: be, walk, locate, navigate, |, withing, source, historic, muni, kid\n",
      "27: be, fill, walk, locate, grow, offer, try, explore, *, tour\n",
      "28: take, be, walk, offer, allow, explore, check, know, 's, try\n",
      "29: be, provide, step, home, orient, help, walk, do, locate, welcome\n",
      "30: be, get, go, have, walk, locate, offer, note, dine, beat\n",
      "31: s, be, take, locate, explore, draw, restaurants, watch, block, visit\n",
      "32: be, look, stroll, have, say, cover, even, increase, score, keep\n",
      "33: be, have, recommend, locate, make, multiple, bring, look, drive, take\n",
      "34: be, give, love, have, locate, know, do, grab, bring, stop\n",
      "35: be, want, have, offer, explore, go, do, locate, feel, make\n",
      "36: be, consider, work, use, walk, locate, center, feature, buzz, expect\n",
      "37: be, find, refer, mean, enjoy, raise, perch, walk, have, sightsee\n",
      "38: include, be, walk, close, locate, bus, know, access, trail, dedicate\n",
      "39: find, be, locate, bustle, have, experience, play, walk, hang, host\n",
      "40: be, change, compare, walk, locate, forget, know, base, dot, interest\n",
      "41: be, call, have, walk, choose, please, locate, enjoy, remain, complaint\n",
      "42: be, amaze, walk, keep, come, locate, combine, share, use, have\n",
      "43: be, pick, think, make, walk, enjoy, rest, locate, vote, return\n",
      "44: 's, be, have, walk, explore, feel, imagine, abut, roam, outerlands\n",
      "45: be, ride, have, catch, locate, move, offer, renowned, spend, go\n",
      "46: boast, lead, hear, inspire, locate, be, charm, admire, spend, fit\n",
      "47: be, miss, locate, meet, t, offer, include, walk, know, choose\n",
      "48: check, do, be, have, walk, offer, catch, 's, explore, swing\n",
      "49: be, make, know, nestle, become, retain, remain, find, rise, catch\n"
     ]
    }
   ],
   "source": [
    "display_results(results_by_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: thrive, appeal, mix\n",
      "1: climb, show, commute, shuttle\n",
      "2: serve, travel, stock, discover\n",
      "3: tuck, maintain, sip\n",
      "4: shop, sit, anywhere, lie, freeway, teem\n",
      "5: neighborhood, surf, lay\n",
      "6: stay, beautiful, support, carry, frame, bart, o\n",
      "7: border, populate, ask, famed\n",
      "8: open, reach, rent, invite, beloved, laugh, designate\n",
      "9: run, create, roll, encompass\n",
      "10: stun\n",
      "11: din, start, remodel, jump\n",
      "12: name, build, just, evolve, range, detach, wind\n",
      "13: park, list, dolores, jog\n",
      "14: paint, cost\n",
      "15: overlook, connect, breathtaking, melt, remove\n",
      "16: downtown, need, relax, depend\n",
      "17: hide, turn, cook, dance, whisk\n",
      "18: surround, line\n",
      "19: hike, require, pack, mention, set\n",
      "20: put, wander, learn\n",
      "21: eat, drink, lose\n",
      "22: rat\n",
      "23: accord, picnic, buy\n",
      "24: crowd, transform, contain, face\n",
      "25: renovate, hold, develop, dominate\n",
      "26: navigate, |, withing, source, historic, muni, kid\n",
      "27: fill, grow, *, tour\n",
      "28: \n",
      "29: step, home, orient, help, welcome\n",
      "30: note, dine, beat\n",
      "31: s, draw, restaurants\n",
      "32: stroll, cover, even, increase, score\n",
      "33: recommend, multiple\n",
      "34: \n",
      "35: want\n",
      "36: consider, work, center, buzz, expect\n",
      "37: refer, mean, raise, perch, sightsee\n",
      "38: close, bus, access, trail, dedicate\n",
      "39: bustle, experience, play, hang\n",
      "40: change, compare, forget, base, dot, interest\n",
      "41: call, please, complaint\n",
      "42: amaze, combine, share\n",
      "43: pick, think, rest, return\n",
      "44: abut, roam, outerlands\n",
      "45: move, renowned\n",
      "46: boast, lead, hear, inspire, admire, fit\n",
      "47: miss, meet, t\n",
      "48: swing\n",
      "49: retain, rise\n"
     ]
    }
   ],
   "source": [
    "display_results_no_duplicates(results_by_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
