{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "import glob as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data(country, city):\n",
    "    directory = 'data/' + country + '/' + city + '/'\n",
    "    csv_files = [file_name for file_name in glob.glob(directory + '*') if file_name[-4:] == '.csv']\n",
    "    \n",
    "    for file_loc in csv_files:\n",
    "        file_name = file_loc.split('/')[3]\n",
    "        \n",
    "        if file_name == 'listings_sample.csv':\n",
    "            #Read Listing Sample\n",
    "            listing_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "        elif file_name == 'reviews_sample.csv':\n",
    "            #Read Review Sample\n",
    "            reviews_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "        elif file_name == 'neighbourhoods_sample.csv':\n",
    "            #Read Neighborhoods\n",
    "            neighbourhoods_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "    return [listing_sample, reviews_sample, neighbourhoods_sample]\n",
    "\n",
    "\n",
    "def load_full_data(country, city):\n",
    "    directory = 'data/' + country + '/' + city + '/'\n",
    "    csv_files = [file_name for file_name in glob.glob(directory + '*') if file_name[-4:] == '.csv']\n",
    "    \n",
    "    for file_loc in csv_files:\n",
    "        file_name = file_loc.split('/')[3]\n",
    "        \n",
    "        if file_name == 'listings_full.csv':\n",
    "            #Read Listings\n",
    "            listings_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "        elif file_name == 'reviews_full.csv':\n",
    "            #Read Reviews\n",
    "            reviews_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "        elif file_name == 'calendar_full.csv':\n",
    "            #Read Calendar\n",
    "            calendar_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "    return [listings_full, reviews_full, calendar_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_sf = pd.read_csv('../sf/listings_detailed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_listing_full(listing_full_data):\n",
    "    \"\"\"Cleans listing_full.csv data\"\"\"\n",
    "    # Input Data\n",
    "    df = listing_full_data\n",
    "    \n",
    "    # String to Datetime\n",
    "    df['last_scraped'] = pd.to_datetime(df['last_scraped'])\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "    df['calendar_last_scraped'] = pd.to_datetime(df['calendar_last_scraped'])\n",
    "    df['first_review'] = pd.to_datetime(df['first_review'])\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "    \n",
    "    # String to Numeric\n",
    "    df['host_response_rate'] = pd.to_numeric(df['host_response_rate'].str[:-1]) / 100\n",
    "    df['price'] = pd.to_numeric(df['price'].str[1:].str.replace(',',''))\n",
    "    df['weekly_price'] = pd.to_numeric(df['weekly_price'].str[1:].str.replace(',',''))\n",
    "    df['monthly_price'] = pd.to_numeric(df['monthly_price'].str[1:].str.replace(',',''))\n",
    "    df['security_deposit'] = pd.to_numeric(df['security_deposit'].str[1:].str.replace(',',''))\n",
    "    df['cleaning_fee'] = pd.to_numeric(df['cleaning_fee'].str[1:].str.replace(',',''))\n",
    "    df['extra_people'] = pd.to_numeric(df['extra_people'].str[1:].str.replace(',',''))\n",
    "\n",
    "    # t/f to Numeric\n",
    "    df['host_is_superhost'] = (df['host_is_superhost'] == \"t\").astype(int)\n",
    "    df['host_has_profile_pic'] = (df['host_has_profile_pic'] == \"t\").astype(int)\n",
    "    df['host_identity_verified'] = (df['host_identity_verified'] == \"t\").astype(int)\n",
    "    df['is_location_exact'] = (df['is_location_exact'] == \"t\").astype(int)\n",
    "    df['has_availability'] = (df['has_availability'] == \"t\").astype(int)\n",
    "    df['requires_license'] = (df['requires_license'] == \"t\").astype(int)\n",
    "    df['instant_bookable'] = (df['instant_bookable'] == \"t\").astype(int)\n",
    "    df['is_business_travel_ready'] = (df['is_business_travel_ready'] == \"t\").astype(int)\n",
    "    df['require_guest_profile_picture'] = (df['require_guest_profile_picture'] == \"t\").astype(int)\n",
    "    df['require_guest_phone_verification'] = (df['require_guest_phone_verification'] == \"t\").astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_listings_sf = clean_listing_full(listings_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_detailed = clean_listings_sf.copy()\n",
    "\n",
    "ID = list(listings_detailed.iloc[:,:2].columns)\n",
    "\n",
    "ABOUT_COLS = list(listings_detailed.iloc[:,3:15].columns)\n",
    "\n",
    "PICS_COLS = list(listings_detailed.iloc[:,15:19].columns)\n",
    "\n",
    "HOST_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('host')])\n",
    "\n",
    "NEIGHBORHOOD_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('neighbourhood')])\n",
    "\n",
    "LOCATION_COLS = list(listings_detailed.iloc[:,37:51].columns)\n",
    "\n",
    "PROPERTY_COLS = list(listings_detailed.iloc[:,51:60].columns)\n",
    "\n",
    "PRICE_COLS = list(listings_detailed.iloc[:,60:67].columns)\n",
    "\n",
    "NIGHTS_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('mum')])\n",
    "\n",
    "AVAILABILITY_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('availability')])\n",
    "\n",
    "REVIEW_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('review')])\n",
    "\n",
    "SCRAPING_COLS = ['scrape_id','calendar_updated','calendar_last_scraped']\n",
    "\n",
    "ELSE_COLS = ['requires_license', 'license', 'jurisdiction_names', 'instant_bookable',\\\n",
    "             'is_business_travel_ready', 'cancellation_policy', 'require_guest_profile_picture',\\\n",
    "             'require_guest_phone_verification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_info = clean_listings_sf[ID + NEIGHBORHOOD_COLS + ABOUT_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7198 entries, 0 to 7197\n",
      "Data columns (total 18 columns):\n",
      "id                              7198 non-null int64\n",
      "listing_url                     7198 non-null object\n",
      "host_neighbourhood              6559 non-null object\n",
      "neighbourhood                   6660 non-null object\n",
      "neighbourhood_cleansed          7198 non-null object\n",
      "neighbourhood_group_cleansed    0 non-null float64\n",
      "last_scraped                    7198 non-null datetime64[ns]\n",
      "name                            7198 non-null object\n",
      "summary                         7000 non-null object\n",
      "space                           6109 non-null object\n",
      "description                     7183 non-null object\n",
      "experiences_offered             7198 non-null object\n",
      "neighborhood_overview           5310 non-null object\n",
      "notes                           4486 non-null object\n",
      "transit                         5238 non-null object\n",
      "access                          4794 non-null object\n",
      "interaction                     4931 non-null object\n",
      "house_rules                     5307 non-null object\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(15)\n",
      "memory usage: 1012.3+ KB\n"
     ]
    }
   ],
   "source": [
    "neighborhood_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews = neighborhood_info[['id','neighbourhood_cleansed','neighborhood_overview']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean & Tokenize Overview Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Initialize Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Get Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Get Puncuations\n",
    "punctuations = set(string.punctuation)\n",
    "\n",
    "def clean_text(doc):\n",
    "    \n",
    "    # remove all ascii\n",
    "    doc = re.sub(r'[^\\x00-\\x7F]+',' ', doc)\n",
    "\n",
    "    # Tokenize, Lemmatize, and Remove Stopwords\n",
    "    tokens = [lemmatizer.lemmatize(word).lower() for word in nltk.word_tokenize(doc) if word.lower() not in set(stop_words | punctuations)]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean & Tokenize Overviews\n",
    "neighborhood_overviews['tokens'] = neighborhood_overviews['neighborhood_overview'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews['clean_overviews'] = neighborhood_overviews['tokens'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_sentences(data):\n",
    "    # Tokenize each sentence into words: token_sentences\n",
    "    token_sentences = [nltk.word_tokenize(re.sub(r'[^\\x00-\\x7F]+',' ', sent)) for sent in data]\n",
    "\n",
    "    # Tag each tokenized sentence into parts of speech: pos_sentences\n",
    "    pos_sentences = [nltk.pos_tag(sent) for sent in token_sentences]\n",
    "    return pos_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TextExtraction with DS Skills Listing\n",
    "pos_overviews_neighborhood = get_pos_sentences(neighborhood_overviews['neighborhood_overview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjectives(pos_sentences):\n",
    "    \"\"\"Adjective List\"\"\"\n",
    "    # Codes\n",
    "    adj_code = ['JJ','JJR','JJS']\n",
    "\n",
    "    # Get List of Adjectives\n",
    "    adj_list = [[word[0].lower() for word in sent if word[1] in adj_code] for sent in pos_sentences]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    adj_lem_list = [[lemmatizer.lemmatize(adj, 'a') for adj in adj_sent] for adj_sent in adj_list]\n",
    "        \n",
    "    return adj_lem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_overviews_neighborhood = get_adjectives(pos_overviews_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews = neighborhood_overviews.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews['adjectives'] = pd.Series(adj_overviews_neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_texts = list(neighborhood_overviews['adjectives'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(token_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in token_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import time\n",
    "ldam = LdaMulticore\n",
    "\n",
    "num_topics = 50\n",
    "num_words = 10\n",
    "passes = 50\n",
    "\n",
    "# Get Start Time\n",
    "start_time = time.time()\n",
    "\n",
    "# LDA Model\n",
    "ldam_model = ldam(common_corpus, num_topics=num_topics, id2word=common_dictionary, passes=passes)\n",
    "model_end_time = time.time() # Model End Time\n",
    "\n",
    "# LDA Results\n",
    "results = ldam_model.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "result_time = time.time() # Results Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldam_model.save('../models/ldam_neighborhood_overviews_50topics_10words_50passes_adj.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results):\n",
    "    for index, results in results:\n",
    "        print(str(index) + ': ' + str(', '.join(results.split('\"')[1::2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: many, family-friendly, beautiful, busy, 10-minute, short, diverse, safe, resort-like, urban\n",
      "1: friendly, hot, best, active, large, new, sunny, old, second, sought-after\n",
      "2: nearby, such, many, private, other, more, short, lively, geographic, difficult\n",
      "3: famous, great, many, favorite, french, such, nitty-gritty, original, beautiful, deep\n",
      "4: quiet, safe, residential, beautiful, many, clean, peaceful, other, best, short\n",
      "5: less, many, beautiful, first, easy, retail, central, trendy, mixed, various\n",
      "6: available, few, short, quiet, cheese, new, enough, good, nail, public\n",
      "7: ethnic, other, few, trendy, great, large, artisan, gourmet, near, authentic\n",
      "8: easy, popular, beautiful, vibrant, best, central, incredible, other, sunny, former\n",
      "9: classic, quick, stunning, great, 24th, iconic, unique, few, national, other\n",
      "10: tech, late, great, short, commercial, industrial, sweet, furnished, unique, several\n",
      "11: central, desirable, vibrant, residential, local, best, such, memorable, painted, 5-10\n",
      "12: fantastic, hidden, russian, best, famous, many, particular, residential, small, crooked\n",
      "13: trendy, convenient, victorian, iconic, green, many, modern, neighborhood, central, public\n",
      "14: wonderful, best, more, half, outdoor, typical, east, vibrant, few, peruvian\n",
      "15: top, super, southern, cool, awesome, quaint, other, residential, beautiful, casual\n",
      "16: flat, old, s, sure, authentic, best, foodie, colorful, plenty, popular\n",
      "17: small, upscale, open, spectacular, commercial, main, high, beautiful, furnished, prestigious\n",
      "18: downtown, quiet, financial, tree-lined, many, easy, other, quick, such, north\n",
      "19: perfect, safe, ocean, many, pleasant, immediate, last, excellent, great, other\n",
      "20: historic, walkable, best, few, many, other, old, flat, short, ever-increasing\n",
      "21: great, true, min, natural, excellent, local, cafe, only, ten, japanese\n",
      "22: next, great, eclectic, huge, many, least, nice, nearby, exceptional, vibrant\n",
      "23: whole, italian, japanese, chinese, short, vietnamese, many, asian, residential, other\n",
      "24: different, few, bohemian, homeless, little, most, famous, beat, aware, comfortable\n",
      "25: free, best, scenic, hip, many, lively, japanese, high, most, italian\n",
      "26: more, great, best, happy, favorite, rich, famous, large, regular, few\n",
      "27: great, many, few, much, short, little, more, nice, beautiful, most\n",
      "28: best, accessible, little, few, own, other, panoramic, cheap, muni, beautiful\n",
      "29: several, new, major, many, best, vibrant, fast, s, coveted, san\n",
      "30: gorgeous, steep, victorian, more, few, beautiful, red, 15-min, n, hop-off\n",
      "31: close, golden, short, many, south, dry, japanese, best, large, few\n",
      "32: right, wide, front, central, american, easy, favorite, best, chic, more\n",
      "33: multiple, fun, easy, quiet, great, inner, several, japanese, fog, nice\n",
      "34: good, nice, cute, little, many, short, few, french, vibrant, popular\n",
      "35: amazing, few, short, sunny, western, best, public, light, little, residential\n",
      "36: adjacent, most, quiet, best, residential, quintessential, minute, more, peaceful, full\n",
      "37: local, other, great, many, few, sunny, short, welcome, available, excellent\n",
      "38: high, ideal, many, best, new, former, s, future, charming, custom-blended\n",
      "39: numerous, live, warm, cultural, commercial, asian, sunny, other, urban, large\n",
      "40: urban, fine, exciting, dynamic, vibrant, short, large, famous, historic, notorious\n",
      "41: diverse, excellent, young, fabulous, best, urban, delicious, famous, furnished, fine\n",
      "42: public, easy, quiet, safe, central, short, more, terrific, other, quick\n",
      "43: entire, best, long, able, bi-rite, small, nightlife, other, short, more\n",
      "44: delicious, colorful, incredible, special, urban, little, international, social, botanical, regular\n",
      "45: large, best, original, easy, residential, eastern, s, financial, high-rise, many\n",
      "46: full, historical, many, mile, personal, same, daily, rich, delicious, few\n",
      "47: traditional, favorite, pretty, nearby, cozy, green, major, central, new, hidden\n",
      "48: lovely, 10-15, interesting, many, low, other, west, historic, beautiful, excellent\n",
      "49: fresh, independent, magnificent, convenient, real, many, romantic, picnic, delightful, stylish\n"
     ]
    }
   ],
   "source": [
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_no_duplicates(results):\n",
    "    all_lists = []\n",
    "    for index, result in results:\n",
    "        all_lists = all_lists + result.split('\"')[1::2]\n",
    "    \n",
    "    # Get Counts of each word\n",
    "    counts = pd.Series(all_lists).value_counts()\n",
    "    no_duplicates = counts[counts == 1].index\n",
    "    \n",
    "    for index, result in results:\n",
    "        print(str(index) + ': ' + str(', '.join([word for word in result.split('\"')[1::2] if word in no_duplicates])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: family-friendly, busy, 10-minute, resort-like\n",
      "1: friendly, hot, active, second, sought-after\n",
      "2: private, geographic, difficult\n",
      "3: nitty-gritty, deep\n",
      "4: clean\n",
      "5: less, first, retail, mixed, various\n",
      "6: cheese, enough, nail\n",
      "7: ethnic, artisan, gourmet, near\n",
      "8: \n",
      "9: classic, stunning, 24th, national\n",
      "10: tech, late, industrial, sweet\n",
      "11: desirable, memorable, painted, 5-10\n",
      "12: fantastic, russian, particular, crooked\n",
      "13: modern, neighborhood\n",
      "14: wonderful, half, outdoor, typical, east, peruvian\n",
      "15: top, super, southern, cool, awesome, quaint, casual\n",
      "16: sure, foodie, plenty\n",
      "17: upscale, open, spectacular, main, prestigious\n",
      "18: downtown, tree-lined, north\n",
      "19: perfect, ocean, pleasant, immediate, last\n",
      "20: walkable, ever-increasing\n",
      "21: true, min, natural, cafe, only, ten\n",
      "22: next, eclectic, huge, least, exceptional\n",
      "23: whole, chinese, vietnamese\n",
      "24: different, bohemian, homeless, beat, aware, comfortable\n",
      "25: free, scenic, hip\n",
      "26: happy\n",
      "27: much\n",
      "28: accessible, own, panoramic, cheap, muni\n",
      "29: fast, coveted, san\n",
      "30: gorgeous, steep, red, 15-min, n, hop-off\n",
      "31: close, golden, south, dry\n",
      "32: right, wide, front, american, chic\n",
      "33: multiple, fun, inner, fog\n",
      "34: cute\n",
      "35: amazing, western, light\n",
      "36: adjacent, quintessential, minute\n",
      "37: welcome\n",
      "38: ideal, future, charming, custom-blended\n",
      "39: numerous, live, warm, cultural\n",
      "40: exciting, dynamic, notorious\n",
      "41: young, fabulous\n",
      "42: terrific\n",
      "43: entire, long, able, bi-rite, nightlife\n",
      "44: special, international, social, botanical\n",
      "45: eastern, high-rise\n",
      "46: historical, mile, personal, same, daily\n",
      "47: traditional, pretty, cozy\n",
      "48: lovely, 10-15, interesting, low, west\n",
      "49: fresh, independent, magnificent, real, romantic, picnic, delightful, stylish\n"
     ]
    }
   ],
   "source": [
    "display_results_no_duplicates(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_by_neighborhood = neighborhood_overviews.groupby('neighbourhood_cleansed')[['adjectives']].apply(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_texts_by_neighborhood = list(tokens_by_neighborhood['adjectives'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary_by_neighborhood = Dictionary(token_texts_by_neighborhood)\n",
    "common_corpus_by_neighborhood = [common_dictionary_by_neighborhood.doc2bow(text) for text in token_texts_by_neighborhood]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import time\n",
    "ldam = LdaMulticore\n",
    "\n",
    "num_topics = 50\n",
    "num_words = 10\n",
    "passes = 50\n",
    "\n",
    "# Get Start Time\n",
    "start_time = time.time()\n",
    "\n",
    "# LDA Model\n",
    "ldam_model_by_neighborhood = ldam(common_corpus_by_neighborhood, num_topics=num_topics, id2word=common_dictionary_by_neighborhood, passes=passes)\n",
    "model_end_time = time.time() # Model End Time\n",
    "\n",
    "# LDA Results\n",
    "results_by_neighborhood = ldam_model_by_neighborhood.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "result_time = time.time() # Results Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldam_model_by_neighborhood.save('../models/ldam_overview_by_neighborhood_50topics_10words_50passes_adj.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: great, many, best, easy, famous, public, central, short, few, safe\n",
      "1: many, best, great, easy, public, quiet, few, vibrant, new, beautiful\n",
      "2: best, great, many, other, quiet, few, safe, public, local, easy\n",
      "3: best, many, great, few, local, public, vibrant, other, easy, s\n",
      "4: great, many, urban, colorful, little, delicious, best, incredible, famous, quiet\n",
      "5: central, public, victorian, many, trendy, famous, low, green, iconic, residential\n",
      "6: many, best, great, easy, s, quiet, local, central, short, new\n",
      "7: high, public, urban, many, adjacent, quiet, interested, short, easy, breath-taking\n",
      "8: great, many, nitty-gritty, famous, original, such, favorite, best, other, iconic\n",
      "9: great, many, small, quiet, affluent, tree-lined, short, easy, local, other\n",
      "10: best, great, quiet, many, public, few, local, safe, famous, easy\n",
      "11: great, many, quiet, best, safe, easy, short, beautiful, few, public\n",
      "12: great, best, many, quiet, few, easy, famous, short, local, public\n",
      "13: best, many, great, local, beautiful, quiet, easy, few, public, central\n",
      "14: many, best, great, public, central, famous, trendy, vibrant, other, few\n",
      "15: great, many, public, easy, few, best, short, other, famous, residential\n",
      "16: quiet, safe, easy, great, residential, many, public, local, nice, few\n",
      "17: elevated, best, many, few, great, famous, quiet, vibrant, s, short\n",
      "18: local, great, few, short, small, public, quiet, main, friendly, residential\n",
      "19: beautiful, easy, incredible, popular, central, vibrant, former, best, many, good\n",
      "20: best, great, many, quiet, short, easy, safe, beautiful, famous, several\n",
      "21: s, major, best, many, new, several, vibrant, fast, financial, high-rise\n",
      "22: great, many, best, quiet, public, few, more, short, urban, other\n",
      "23: best, many, great, few, local, new, quiet, vibrant, more, sunny\n",
      "24: best, great, many, other, quiet, sunny, local, safe, more, new\n",
      "25: quiet, great, safe, many, japanese, local, residential, easy, public, best\n",
      "26: great, many, best, easy, quiet, few, local, other, vibrant, safe\n",
      "27: many, great, best, s, few, new, easy, urban, famous, vibrant\n",
      "28: urban, large, famous, public, short, fine, historic, vibrant, former, theatrical\n",
      "29: best, new, great, many, major, easy, several, famous, large, s\n",
      "30: best, many, public, central, victorian, trendy, new, green, famous, easy\n",
      "31: many, high, great, tourist-popular, easy, new, public, above-ground, hopping, few\n",
      "32: many, best, s, new, major, several, vibrant, fast, great, easy\n",
      "33: great, many, best, easy, few, quiet, famous, beautiful, public, safe\n",
      "34: many, best, great, central, easy, vibrant, new, s, public, famous\n",
      "35: best, many, great, central, new, s, famous, easy, major, few\n",
      "36: great, many, best, urban, central, more, public, victorian, famous, international\n",
      "37: great, best, many, few, local, easy, public, new, quiet, residential\n",
      "38: great, famous, rich, regular, large, italian, fantastic, original, wild, uphill\n",
      "39: many, best, great, few, urban, central, vibrant, public, easy, historic\n",
      "40: great, quiet, local, many, few, public, best, little, more, safe\n",
      "41: great, best, many, easy, vibrant, new, other, few, short, quiet\n",
      "42: best, great, many, few, public, central, famous, trendy, quiet, vibrant\n",
      "43: best, great, quiet, many, public, easy, safe, beautiful, vibrant, local\n",
      "44: best, great, many, colorful, few, vibrant, quiet, other, famous, beautiful\n",
      "45: best, public, many, famous, central, great, easy, new, quiet, urban\n",
      "46: best, many, great, new, s, few, more, public, easy, residential\n",
      "47: many, russian, great, italian, best, safe, easy, short, other, beautiful\n",
      "48: great, safe, local, close, japanese, diverse, quiet, easy, public, residential\n",
      "49: best, great, many, quiet, few, easy, sunny, other, local, public\n"
     ]
    }
   ],
   "source": [
    "display_results(results_by_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "1: \n",
      "2: \n",
      "3: \n",
      "4: delicious\n",
      "5: low\n",
      "6: \n",
      "7: adjacent, interested, breath-taking\n",
      "8: nitty-gritty, such, favorite\n",
      "9: affluent, tree-lined\n",
      "10: \n",
      "11: \n",
      "12: \n",
      "13: \n",
      "14: \n",
      "15: \n",
      "16: nice\n",
      "17: elevated\n",
      "18: main, friendly\n",
      "19: popular, good\n",
      "20: \n",
      "21: financial, high-rise\n",
      "22: \n",
      "23: \n",
      "24: \n",
      "25: \n",
      "26: \n",
      "27: \n",
      "28: fine, theatrical\n",
      "29: \n",
      "30: \n",
      "31: tourist-popular, above-ground, hopping\n",
      "32: \n",
      "33: \n",
      "34: \n",
      "35: \n",
      "36: international\n",
      "37: \n",
      "38: rich, regular, fantastic, wild, uphill\n",
      "39: \n",
      "40: \n",
      "41: \n",
      "42: \n",
      "43: \n",
      "44: \n",
      "45: \n",
      "46: \n",
      "47: russian\n",
      "48: close, diverse\n",
      "49: \n"
     ]
    }
   ],
   "source": [
    "display_results_no_duplicates(results_by_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
