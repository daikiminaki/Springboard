{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling Neighborhood Overview: Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "import glob as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data(country, city):\n",
    "    directory = 'data/' + country + '/' + city + '/'\n",
    "    csv_files = [file_name for file_name in glob.glob(directory + '*') if file_name[-4:] == '.csv']\n",
    "    \n",
    "    for file_loc in csv_files:\n",
    "        file_name = file_loc.split('/')[3]\n",
    "        \n",
    "        if file_name == 'listings_sample.csv':\n",
    "            #Read Listing Sample\n",
    "            listing_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "        elif file_name == 'reviews_sample.csv':\n",
    "            #Read Review Sample\n",
    "            reviews_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "        elif file_name == 'neighbourhoods_sample.csv':\n",
    "            #Read Neighborhoods\n",
    "            neighbourhoods_sample = pd.read_csv(file_loc)\n",
    "            \n",
    "    return [listing_sample, reviews_sample, neighbourhoods_sample]\n",
    "\n",
    "\n",
    "def load_full_data(country, city):\n",
    "    directory = 'data/' + country + '/' + city + '/'\n",
    "    csv_files = [file_name for file_name in glob.glob(directory + '*') if file_name[-4:] == '.csv']\n",
    "    \n",
    "    for file_loc in csv_files:\n",
    "        file_name = file_loc.split('/')[3]\n",
    "        \n",
    "        if file_name == 'listings_full.csv':\n",
    "            #Read Listings\n",
    "            listings_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "        elif file_name == 'reviews_full.csv':\n",
    "            #Read Reviews\n",
    "            reviews_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "        elif file_name == 'calendar_full.csv':\n",
    "            #Read Calendar\n",
    "            calendar_full = pd.read_csv(file_loc).drop(columns=['Unnamed: 0'])\n",
    "            \n",
    "    return [listings_full, reviews_full, calendar_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_sf = pd.read_csv('../sf/listings_detailed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_listing_full(listing_full_data):\n",
    "    \"\"\"Cleans listing_full.csv data\"\"\"\n",
    "    # Input Data\n",
    "    df = listing_full_data\n",
    "    \n",
    "    # String to Datetime\n",
    "    df['last_scraped'] = pd.to_datetime(df['last_scraped'])\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "    df['calendar_last_scraped'] = pd.to_datetime(df['calendar_last_scraped'])\n",
    "    df['first_review'] = pd.to_datetime(df['first_review'])\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "    \n",
    "    # String to Numeric\n",
    "    df['host_response_rate'] = pd.to_numeric(df['host_response_rate'].str[:-1]) / 100\n",
    "    df['price'] = pd.to_numeric(df['price'].str[1:].str.replace(',',''))\n",
    "    df['weekly_price'] = pd.to_numeric(df['weekly_price'].str[1:].str.replace(',',''))\n",
    "    df['monthly_price'] = pd.to_numeric(df['monthly_price'].str[1:].str.replace(',',''))\n",
    "    df['security_deposit'] = pd.to_numeric(df['security_deposit'].str[1:].str.replace(',',''))\n",
    "    df['cleaning_fee'] = pd.to_numeric(df['cleaning_fee'].str[1:].str.replace(',',''))\n",
    "    df['extra_people'] = pd.to_numeric(df['extra_people'].str[1:].str.replace(',',''))\n",
    "\n",
    "    # t/f to Numeric\n",
    "    df['host_is_superhost'] = (df['host_is_superhost'] == \"t\").astype(int)\n",
    "    df['host_has_profile_pic'] = (df['host_has_profile_pic'] == \"t\").astype(int)\n",
    "    df['host_identity_verified'] = (df['host_identity_verified'] == \"t\").astype(int)\n",
    "    df['is_location_exact'] = (df['is_location_exact'] == \"t\").astype(int)\n",
    "    df['has_availability'] = (df['has_availability'] == \"t\").astype(int)\n",
    "    df['requires_license'] = (df['requires_license'] == \"t\").astype(int)\n",
    "    df['instant_bookable'] = (df['instant_bookable'] == \"t\").astype(int)\n",
    "    df['is_business_travel_ready'] = (df['is_business_travel_ready'] == \"t\").astype(int)\n",
    "    df['require_guest_profile_picture'] = (df['require_guest_profile_picture'] == \"t\").astype(int)\n",
    "    df['require_guest_phone_verification'] = (df['require_guest_phone_verification'] == \"t\").astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_listings_sf = clean_listing_full(listings_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_detailed = clean_listings_sf.copy()\n",
    "\n",
    "ID = list(listings_detailed.iloc[:,:2].columns)\n",
    "\n",
    "ABOUT_COLS = list(listings_detailed.iloc[:,3:15].columns)\n",
    "\n",
    "PICS_COLS = list(listings_detailed.iloc[:,15:19].columns)\n",
    "\n",
    "HOST_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('host')])\n",
    "\n",
    "NEIGHBORHOOD_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('neighbourhood')])\n",
    "\n",
    "LOCATION_COLS = list(listings_detailed.iloc[:,37:51].columns)\n",
    "\n",
    "PROPERTY_COLS = list(listings_detailed.iloc[:,51:60].columns)\n",
    "\n",
    "PRICE_COLS = list(listings_detailed.iloc[:,60:67].columns)\n",
    "\n",
    "NIGHTS_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('mum')])\n",
    "\n",
    "AVAILABILITY_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('availability')])\n",
    "\n",
    "REVIEW_COLS = list(listings_detailed.columns[listings_detailed.columns.str.contains('review')])\n",
    "\n",
    "SCRAPING_COLS = ['scrape_id','calendar_updated','calendar_last_scraped']\n",
    "\n",
    "ELSE_COLS = ['requires_license', 'license', 'jurisdiction_names', 'instant_bookable',\\\n",
    "             'is_business_travel_ready', 'cancellation_policy', 'require_guest_profile_picture',\\\n",
    "             'require_guest_phone_verification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_info = clean_listings_sf[ID + NEIGHBORHOOD_COLS + ABOUT_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7198 entries, 0 to 7197\n",
      "Data columns (total 18 columns):\n",
      "id                              7198 non-null int64\n",
      "listing_url                     7198 non-null object\n",
      "host_neighbourhood              6559 non-null object\n",
      "neighbourhood                   6660 non-null object\n",
      "neighbourhood_cleansed          7198 non-null object\n",
      "neighbourhood_group_cleansed    0 non-null float64\n",
      "last_scraped                    7198 non-null datetime64[ns]\n",
      "name                            7198 non-null object\n",
      "summary                         7000 non-null object\n",
      "space                           6109 non-null object\n",
      "description                     7183 non-null object\n",
      "experiences_offered             7198 non-null object\n",
      "neighborhood_overview           5310 non-null object\n",
      "notes                           4486 non-null object\n",
      "transit                         5238 non-null object\n",
      "access                          4794 non-null object\n",
      "interaction                     4931 non-null object\n",
      "house_rules                     5307 non-null object\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(15)\n",
      "memory usage: 1012.3+ KB\n"
     ]
    }
   ],
   "source": [
    "neighborhood_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews = neighborhood_info[['id','neighbourhood_cleansed','neighborhood_overview']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean & Tokenize Overview Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Initialize Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Get Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Get Puncuations\n",
    "punctuations = set(string.punctuation)\n",
    "\n",
    "def clean_text(doc):\n",
    "    \n",
    "    # remove all ascii\n",
    "    doc = re.sub(r'[^\\x00-\\x7F]+',' ', doc)\n",
    "\n",
    "    # Tokenize, Lemmatize, and Remove Stopwords\n",
    "    tokens = [lemmatizer.lemmatize(word).lower() for word in nltk.word_tokenize(doc) if word.lower() not in set(stop_words | punctuations)]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean & Tokenize Overviews\n",
    "neighborhood_overviews['tokens'] = neighborhood_overviews['neighborhood_overview'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews['clean_overviews'] = neighborhood_overviews['tokens'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_sentences(data):\n",
    "    # Tokenize each sentence into words: token_sentences\n",
    "    token_sentences = [nltk.word_tokenize(re.sub(r'[^\\x00-\\x7F]+',' ', sent)) for sent in data]\n",
    "\n",
    "    # Tag each tokenized sentence into parts of speech: pos_sentences\n",
    "    pos_sentences = [nltk.pos_tag(sent) for sent in token_sentences]\n",
    "    return pos_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TextExtraction with DS Skills Listing\n",
    "pos_overviews_neighborhood = get_pos_sentences(neighborhood_overviews['neighborhood_overview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verbs(pos_sentences):\n",
    "    \"\"\"Return Verbs\"\"\"\n",
    "    # Codes\n",
    "    verb_code = ['VBG','VB','VBD','VBN','VBZ']\n",
    "\n",
    "    # Get List of Adjectives\n",
    "    verb_list = [[word[0].lower() for word in sent if word[1] in verb_code] for sent in pos_sentences]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    verb_lem_list = [[lemmatizer.lemmatize(verb, 'v') for verb in verb_sent] for verb_sent in verb_list]\n",
    "        \n",
    "    return verb_lem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_overviews_neighborhood = get_verbs(pos_overviews_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews = neighborhood_overviews.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_overviews['verbs'] = pd.Series(verbs_overviews_neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_texts = list(neighborhood_overviews['verbs'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(token_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in token_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import time\n",
    "ldam = LdaMulticore\n",
    "\n",
    "num_topics = 50\n",
    "num_words = 10\n",
    "passes = 50\n",
    "\n",
    "# Get Start Time\n",
    "start_time = time.time()\n",
    "\n",
    "# LDA Model\n",
    "ldam_model = ldam(common_corpus, num_topics=num_topics, id2word=common_dictionary, passes=passes)\n",
    "model_end_time = time.time() # Model End Time\n",
    "\n",
    "# LDA Results\n",
    "results = ldam_model.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "result_time = time.time() # Results Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldam_model.save('../models/ldam_neighborhood_overviews_50topics_10words_50passes_verbs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results):\n",
    "    for index, results in results:\n",
    "        print(str(index) + ': ' + str(', '.join(results.split('\"')[1::2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: provide, be, watch, overlook, rent, breathtaking, have, walk, remove, locate\n",
      "1: park, be, reach, walk, right, leave, tell, brew, access, witness\n",
      "2: be, locate, walk, have, offer, boast, lend, inspire, access, trail\n",
      "3: be, bring, make, leave, recommend, read, do, have, park, locate\n",
      "4: be, consider, have, seek, create, 's, offer, welcome, dominate, fill\n",
      "5: be, serve, walk, have, cover, offer, dine, sandwich, share, enjoy\n",
      "6: love, open, be, do, lay, surf, view, hold, book, explore\n",
      "7: 's, be, surround, walk, swim, offer, have, explore, cut, streets\n",
      "8: din, be, list, head, bus, please, walk, describe, increase, await\n",
      "9: amaze, be, orient, walk, ask, own, throw, trail, hip, underrate\n",
      "10: make, stay, miss, be, offer, explore, take, invite, reach, afford\n",
      "11: walk, be, have, hear, boast, remodel, found, name, ~, please\n",
      "12: find, be, locate, bustle, step, walk, border, multiple, mention, lie\n",
      "13: be, walk, try, offer, explore, fill, grow, locate, thrive, appeal\n",
      "14: be, know, locate, include, offer, center, t, miss, let, have\n",
      "15: be, eat, drink, pick, have, hang, walk, cafes, think, enjoy\n",
      "16: use, walk, be, forget, take, check, locate, historic, hit, receive\n",
      "17: be, locate, walk, help, climb, mean, choose, meet, provide, do\n",
      "18: be, come, block, walk, buzz, consider, combine, experience, glitter, invite\n",
      "19: be, line, lead, walk, just, set, range, paint, beautiful, inspire\n",
      "20: be, work, evoke, accord, breathtaking, put, ride, drench, south, sip\n",
      "21: be, nestle, become, retain, remain, make, rise, find, know, fame\n",
      "22: be, rat, have, locate, excite, vary, find, live, enjoy, undergo\n",
      "23: be, keep, have, 's, bring, cost, give, do, build, get\n",
      "24: look, be, find, like, 's, browse, learn, beach, follow, shop\n",
      "25: be, have, go, walk, find, offer, clean, prepare, stay, make\n",
      "26: be, drive, stun, dolores, require, expect, have, sleep, raise, locate\n",
      "27: include, be, enjoy, walk, have, stock, own, laugh, give, note\n",
      "28: take, be, go, locate, commute, walk, come, shuttle, occupy, 's\n",
      "29: run, have, walk, be, offer, base, take, enjoy, dinner, west\n",
      "30: give, start, be, bike, offer, find, ten, 's, meet, explore\n",
      "31: be, feature, need, want, name, neighborhood, happen, evolve, water, develop\n",
      "32: be, downtown, walk, locate, home, border, anchor, take, rout, skip\n",
      "33: be, call, charm, walk, have, connect, enjoy, offer, seclude, roam\n",
      "34: be, go, feel, walk, tour, boast, build, emerge, check, stop\n",
      "35: situate, be, walk, go, discover, coffee, sit, buy, offer, table\n",
      "36: have, be, offer, anywhere, become, freeway, hide, vote, enjoy, face\n",
      "37: catch, renowned, be, offer, taste, seem, go, have, spend, crook\n",
      "38: s, be, pack, pull, bookstores, leave, push, wander, spot, walk\n",
      "39: be, grab, melt, travel, compare, represent, have, spend, roast, believe\n",
      "40: get, be, have, walk, offer, renovate, appreciate, street, lose, picnic\n",
      "41: be, live, explore, walk, stroll, know, get, situate, doesn, draw\n",
      "42: be, walk, tuck, turn, have, situate, win, jog, contain, worry\n",
      "43: be, close, experience, have, play, host, cook, walk, ocean, dance\n",
      "44: be, explore, ride, put, stop, spend, wander, check, learn, occupy\n",
      "45: o, do, para, restaurantes, sempre, sol, doesn, know, grab, find\n",
      "46: explore, be, offer, check, walk, try, allow, 's, have, catch\n",
      "47: be, see, do, visit, walk, have, relax, change, feel, face\n",
      "48: shop, hike, hide, be, walk, sit, *, relax, twin, enjoy\n",
      "49: be, say, walk, have, feel, offer, stretch, raise, shelter, rise\n"
     ]
    }
   ],
   "source": [
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_no_duplicates(results):\n",
    "    all_lists = []\n",
    "    for index, result in results:\n",
    "        all_lists = all_lists + result.split('\"')[1::2]\n",
    "    \n",
    "    # Get Counts of each word\n",
    "    counts = pd.Series(all_lists).value_counts()\n",
    "    no_duplicates = counts[counts == 1].index\n",
    "    \n",
    "    for index, result in results:\n",
    "        print(str(index) + ': ' + str(', '.join([word for word in result.split('\"')[1::2] if word in no_duplicates])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: watch, overlook, rent, remove\n",
      "1: right, tell, brew, witness\n",
      "2: lend\n",
      "3: recommend, read\n",
      "4: seek, create, welcome, dominate\n",
      "5: serve, cover, dine, sandwich, share\n",
      "6: love, open, lay, surf, view, hold, book\n",
      "7: surround, swim, cut, streets\n",
      "8: din, list, head, bus, describe, increase, await\n",
      "9: amaze, orient, ask, throw, hip, underrate\n",
      "10: afford\n",
      "11: hear, remodel, found, ~\n",
      "12: bustle, step, multiple, mention, lie\n",
      "13: grow, thrive, appeal\n",
      "14: center, t, let\n",
      "15: eat, drink, pick, hang, cafes, think\n",
      "16: use, forget, historic, hit, receive\n",
      "17: help, climb, mean, choose\n",
      "18: block, buzz, combine, glitter\n",
      "19: line, lead, just, set, range, paint, beautiful\n",
      "20: work, evoke, accord, drench, south, sip\n",
      "21: nestle, retain, remain, fame\n",
      "22: rat, excite, vary, undergo\n",
      "23: keep, cost\n",
      "24: look, like, browse, beach, follow\n",
      "25: clean, prepare\n",
      "26: drive, stun, dolores, require, expect, sleep\n",
      "27: stock, laugh, note\n",
      "28: commute, shuttle\n",
      "29: run, base, dinner, west\n",
      "30: start, bike, ten\n",
      "31: feature, need, want, neighborhood, happen, evolve, water, develop\n",
      "32: downtown, home, anchor, rout, skip\n",
      "33: call, charm, connect, seclude, roam\n",
      "34: tour, emerge\n",
      "35: discover, coffee, buy, table\n",
      "36: anywhere, freeway, vote\n",
      "37: renowned, taste, seem, crook\n",
      "38: s, pack, pull, bookstores, push, spot\n",
      "39: melt, travel, compare, represent, roast, believe\n",
      "40: renovate, appreciate, street, lose, picnic\n",
      "41: stroll, draw\n",
      "42: tuck, turn, win, jog, contain, worry\n",
      "43: close, play, host, cook, ocean, dance\n",
      "44: \n",
      "45: o, para, restaurantes, sempre, sol\n",
      "46: allow\n",
      "47: see, visit, change\n",
      "48: hike, *, twin\n",
      "49: say, stretch, shelter\n"
     ]
    }
   ],
   "source": [
    "display_results_no_duplicates(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_by_neighborhood = neighborhood_overviews.groupby('neighbourhood_cleansed')[['verbs']].apply(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_texts_by_neighborhood = list(neighborhood_overviews['verbs'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary_by_neighborhood = Dictionary(token_texts_by_neighborhood)\n",
    "common_corpus_by_neighborhood = [common_dictionary_by_neighborhood.doc2bow(text) for text in token_texts_by_neighborhood]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import time\n",
    "ldam = LdaMulticore\n",
    "\n",
    "num_topics = 50\n",
    "num_words = 10\n",
    "passes = 50\n",
    "\n",
    "# Get Start Time\n",
    "start_time = time.time()\n",
    "\n",
    "# LDA Model\n",
    "ldam_model_by_neighborhood = ldam(common_corpus_by_neighborhood, num_topics=num_topics, id2word=common_dictionary_by_neighborhood, passes=passes)\n",
    "model_end_time = time.time() # Model End Time\n",
    "\n",
    "# LDA Results\n",
    "results_by_neighborhood = ldam_model_by_neighborhood.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "result_time = time.time() # Results Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldam_model_by_neighborhood.save('../models/ldam_overview_by_neighborhood_50topics_10words_50passes_verbs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: be, offer, explore, try, walk, thrive, appeal, mix, allow, stop\n",
      "1: be, climb, take, locate, walk, show, commute, occupy, shuttle, 's\n",
      "2: be, serve, live, find, travel, stock, discover, own, come, give\n",
      "3: be, visit, get, tuck, host, offer, maintain, own, sip, locate\n",
      "4: be, shop, locate, sit, walk, drive, anywhere, lie, freeway, teem\n",
      "5: see, be, watch, neighborhood, walk, do, have, take, surf, lay\n",
      "6: stay, bike, beautiful, support, carry, happen, imagine, frame, bart, o\n",
      "7: be, border, have, say, locate, make, populate, ask, walk, famed\n",
      "8: open, reach, rent, own, be, invite, beloved, laugh, designate, bike\n",
      "9: run, charm, be, have, create, roll, walk, encompass, locate, stop\n",
      "10: be, situate, walk, stun, feel, know, explore, get, happen, live\n",
      "11: be, din, start, grab, locate, walk, remodel, have, love, jump\n",
      "12: be, feature, name, build, just, evolve, range, have, detach, wind\n",
      "13: enjoy, park, be, walk, have, list, dolores, head, leave, jog\n",
      "14: be, have, take, locate, 's, see, paint, know, cost, do\n",
      "15: be, overlook, connect, breathtaking, locate, melt, have, remove, nestle, provide\n",
      "16: be, downtown, need, locate, walk, have, relax, take, know, depend\n",
      "17: be, hide, block, walk, turn, cook, know, dance, situate, whisk\n",
      "18: surround, be, walk, 's, offer, explore, line, try, have, catch\n",
      "19: hike, be, have, leave, walk, require, pack, mention, set, make\n",
      "20: be, locate, explore, put, check, stop, wander, spend, learn, occupy\n",
      "21: be, eat, bring, walk, drink, locate, have, do, grab, lose\n",
      "22: be, have, live, locate, rat, know, become, offer, vote, make\n",
      "23: be, have, see, locate, walk, offer, accord, own, picnic, buy\n",
      "24: be, have, offer, crowd, transform, contain, ride, face, head, locate\n",
      "25: be, come, take, go, have, renovate, hold, develop, locate, dominate\n",
      "26: be, walk, locate, navigate, |, withing, source, historic, muni, kid\n",
      "27: be, fill, walk, locate, grow, offer, try, explore, *, tour\n",
      "28: take, be, walk, offer, allow, explore, check, know, 's, try\n",
      "29: be, provide, step, home, orient, help, walk, do, locate, welcome\n",
      "30: be, get, go, have, walk, locate, offer, note, dine, beat\n",
      "31: s, be, take, locate, explore, draw, restaurants, watch, block, visit\n",
      "32: be, look, stroll, have, say, cover, even, increase, score, keep\n",
      "33: be, have, recommend, locate, make, multiple, bring, look, drive, take\n",
      "34: be, give, love, have, locate, know, do, grab, bring, stop\n",
      "35: be, want, have, offer, explore, go, do, locate, feel, make\n",
      "36: be, consider, work, use, walk, locate, center, feature, buzz, expect\n",
      "37: be, find, refer, mean, enjoy, raise, perch, walk, have, sightsee\n",
      "38: include, be, walk, close, locate, bus, know, access, trail, dedicate\n",
      "39: find, be, locate, bustle, have, experience, play, walk, hang, host\n",
      "40: be, change, compare, walk, locate, forget, know, base, dot, interest\n",
      "41: be, call, have, walk, choose, please, locate, enjoy, remain, complaint\n",
      "42: be, amaze, walk, keep, come, locate, combine, share, use, have\n",
      "43: be, pick, think, make, walk, enjoy, rest, locate, vote, return\n",
      "44: 's, be, have, walk, explore, feel, imagine, abut, roam, outerlands\n",
      "45: be, ride, have, catch, locate, move, offer, renowned, spend, go\n",
      "46: boast, lead, hear, inspire, locate, be, charm, admire, spend, fit\n",
      "47: be, miss, locate, meet, t, offer, include, walk, know, choose\n",
      "48: check, do, be, have, walk, offer, catch, 's, explore, swing\n",
      "49: be, make, know, nestle, become, retain, remain, find, rise, catch\n"
     ]
    }
   ],
   "source": [
    "display_results(results_by_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: thrive, appeal, mix\n",
      "1: climb, show, commute, shuttle\n",
      "2: serve, travel, stock, discover\n",
      "3: tuck, maintain, sip\n",
      "4: shop, sit, anywhere, lie, freeway, teem\n",
      "5: neighborhood, surf, lay\n",
      "6: stay, beautiful, support, carry, frame, bart, o\n",
      "7: border, populate, ask, famed\n",
      "8: open, reach, rent, invite, beloved, laugh, designate\n",
      "9: run, create, roll, encompass\n",
      "10: stun\n",
      "11: din, start, remodel, jump\n",
      "12: name, build, just, evolve, range, detach, wind\n",
      "13: park, list, dolores, jog\n",
      "14: paint, cost\n",
      "15: overlook, connect, breathtaking, melt, remove\n",
      "16: downtown, need, relax, depend\n",
      "17: hide, turn, cook, dance, whisk\n",
      "18: surround, line\n",
      "19: hike, require, pack, mention, set\n",
      "20: put, wander, learn\n",
      "21: eat, drink, lose\n",
      "22: rat\n",
      "23: accord, picnic, buy\n",
      "24: crowd, transform, contain, face\n",
      "25: renovate, hold, develop, dominate\n",
      "26: navigate, |, withing, source, historic, muni, kid\n",
      "27: fill, grow, *, tour\n",
      "28: \n",
      "29: step, home, orient, help, welcome\n",
      "30: note, dine, beat\n",
      "31: s, draw, restaurants\n",
      "32: stroll, cover, even, increase, score\n",
      "33: recommend, multiple\n",
      "34: \n",
      "35: want\n",
      "36: consider, work, center, buzz, expect\n",
      "37: refer, mean, raise, perch, sightsee\n",
      "38: close, bus, access, trail, dedicate\n",
      "39: bustle, experience, play, hang\n",
      "40: change, compare, forget, base, dot, interest\n",
      "41: call, please, complaint\n",
      "42: amaze, combine, share\n",
      "43: pick, think, rest, return\n",
      "44: abut, roam, outerlands\n",
      "45: move, renowned\n",
      "46: boast, lead, hear, inspire, admire, fit\n",
      "47: miss, meet, t\n",
      "48: swing\n",
      "49: retain, rise\n"
     ]
    }
   ],
   "source": [
    "display_results_no_duplicates(results_by_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
